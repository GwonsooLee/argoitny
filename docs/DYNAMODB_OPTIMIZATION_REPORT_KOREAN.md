# DynamoDB ì ‘ê·¼ íŒ¨í„´ ë° ìµœì í™” ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ

**ì‘ì„±ì¼**: 2025-10-11
**ë¶„ì„ ëŒ€ìƒ**: /Users/gwonsoolee/algoitny/backend
**ì´ Repository ì½”ë“œ ë¼ì¸**: 4,083ì¤„

---

## ğŸ“‹ ëª©ì°¨

1. [ì „ì²´ ìš”ì•½](#1-ì „ì²´-ìš”ì•½)
2. [ë¹„íš¨ìœ¨ì ì¸ ì ‘ê·¼ íŒ¨í„´ ìƒì„¸ ë¶„ì„](#2-ë¹„íš¨ìœ¨ì ì¸-ì ‘ê·¼-íŒ¨í„´-ìƒì„¸-ë¶„ì„)
3. [SCAN ì‘ì—… ë¶„ì„ ë° ìµœì í™” ë°©ì•ˆ](#3-scan-ì‘ì—…-ë¶„ì„-ë°-ìµœì í™”-ë°©ì•ˆ)
4. [Hot Partition ë¶„ì„](#4-hot-partition-ë¶„ì„)
5. [TTL ê¶Œì¥ì‚¬í•­ ë° ë¹„ìš© ì ˆê° ê³„ì‚°](#5-ttl-ê¶Œì¥ì‚¬í•­-ë°-ë¹„ìš©-ì ˆê°-ê³„ì‚°)
6. [GSI ìµœì í™” ê¸°íšŒ](#6-gsi-ìµœì í™”-ê¸°íšŒ)
7. [ìƒì„¸ êµ¬í˜„ ë¡œë“œë§µ](#7-ìƒì„¸-êµ¬í˜„-ë¡œë“œë§µ)

---

## 1. ì „ì²´ ìš”ì•½

### 1.1 í˜„ì¬ í…Œì´ë¸” êµ¬ì¡°

```
í…Œì´ë¸”ëª…: algoitny_main
ë¹Œë§ ëª¨ë“œ: PAY_PER_REQUEST (On-Demand)
ìŠ¤íŠ¸ë¦¼: í™œì„±í™” (NEW_AND_OLD_IMAGES)

Primary Key:
- PK (Hash): String
- SK (Range): String

Global Secondary Indexes:
- GSI1: GSI1PK (Hash), GSI1SK (Range) - User ì¸ì¦, Job ìƒíƒœ ì¿¼ë¦¬
- GSI2: GSI2PK (Hash) - Google ID ì¡°íšŒ
- GSI3: GSI3PK (Hash), GSI3SK (Range) - Problem ìƒíƒœ ì¸ë±ìŠ¤
```

### 1.2 ì£¼ìš” ë°œê²¬ì‚¬í•­

| ì˜ì—­ | ì‹¬ê°ë„ | í˜„ì¬ ë¹„ìš© | ìµœì í™” í›„ ì˜ˆìƒ ë¹„ìš© | ì ˆê°ìœ¨ |
|------|--------|-----------|---------------------|--------|
| SCAN ì‘ì—… (5ê°œ ë°œê²¬) | ğŸ”´ ë†’ìŒ | $150/ì›” | $2/ì›” | 98.7% |
| TTL ë¯¸ì ìš© (3ê°œ ì—”í‹°í‹°) | ğŸŸ¡ ì¤‘ê°„ | $30/ì›” | $3/ì›” | 90% |
| Hot Partition (GSI2) | ğŸŸ  ì¤‘ê°„ | $20/ì›” | $5/ì›” | 75% |
| GSI ê³¼ë‹¤ í”„ë¡œì ì…˜ | ğŸŸ¢ ë‚®ìŒ | $10/ì›” | $7/ì›” | 30% |
| **ì „ì²´** | - | **$210/ì›”** | **$17/ì›”** | **91.9%** |

> **ì˜ˆìƒ ì›”ê°„ ë¹„ìš© ì ˆê°**: $193 (~25ë§Œì›)
> **ì—°ê°„ ì ˆê° ì˜ˆìƒ**: $2,316 (~300ë§Œì›)

---

## 2. ë¹„íš¨ìœ¨ì ì¸ ì ‘ê·¼ íŒ¨í„´ ìƒì„¸ ë¶„ì„

### 2.1 âŒ CRITICAL: `list_problems_needing_review()` - Full Table Scan

**íŒŒì¼**: `/Users/gwonsoolee/algoitny/backend/api/dynamodb/repositories/problem_repository.py`
**ë¼ì¸**: 646-690

#### í˜„ì¬ êµ¬í˜„ ì½”ë“œ

```python
def list_problems_needing_review(
    self,
    limit: int = 100
) -> List[Dict[str, Any]]:
    """
    List problems that need admin review (scan operation)
    """
    items = self.scan(
        filter_expression=Attr('tp').eq('prob') &
                        Attr('dat.nrv').eq(True) &
                        Attr('dat.del').eq(False) &
                        Attr('SK').eq('META'),
        limit=limit
    )

    problems = []
    for item in items:
        pk_parts = item['PK'].split('#')
        if len(pk_parts) >= 3:
            platform = pk_parts[1]
            problem_id = '#'.join(pk_parts[2:])

            problems.append({
                'platform': platform,
                'problem_id': problem_id,
                'title': item['dat'].get('tit', ''),
                'problem_url': item['dat'].get('url', ''),
                'tags': item['dat'].get('tag', []),
                'language': item['dat'].get('lng', ''),
                'needs_review': item['dat'].get('nrv', False),
                'review_notes': item['dat'].get('rvn'),
                'verified_by_admin': item['dat'].get('vrf', False),
                'created_at': item.get('crt'),
                'updated_at': item.get('upd')
            })

    problems.sort(key=lambda x: x.get('created_at', 0))
    return problems
```

#### ë¬¸ì œì  ë¶„ì„

1. **Scan Operation**: ì „ì²´ í…Œì´ë¸”ì„ ìŠ¤ìº”í•˜ì—¬ `needs_review=True`ì¸ í•­ëª© í•„í„°ë§
2. **RCU ë¹„ìš©**:
   - í…Œì´ë¸”ì— 10,000ê°œ ì•„ì´í…œ ê°€ì • ì‹œ
   - í‰ê·  ì•„ì´í…œ í¬ê¸°: 2KB
   - Scan RCU = (10,000 items Ã— 2KB) / 4KB = 5,000 RCU
   - ì›” 100íšŒ í˜¸ì¶œ ì‹œ: 500,000 RCU = **$65/ì›”**
3. **ë ˆì´í„´ì‹œ**: í‰ê·  1,500ms (1.5ì´ˆ)
4. **ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸**:
   - ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ ë¡œë”© ì§€ì—°
   - ì‚¬ìš©ì ê²½í—˜ ì €í•˜
   - ì„œë²„ ë¦¬ì†ŒìŠ¤ ê³¼ë‹¤ ì‚¬ìš©

#### ì œì•ˆëœ ìµœì í™” ë°©ì•ˆ

**ì˜µì…˜ 1: GSI4 ìƒì„± (ê¶Œì¥)**

```python
# table_schema.pyì— ì¶”ê°€
'AttributeDefinitions': [
    # ... ê¸°ì¡´ ì •ì˜ë“¤
    {'AttributeName': 'GSI4PK', 'AttributeType': 'S'},
    {'AttributeName': 'GSI4SK', 'AttributeType': 'N'},
],

'GlobalSecondaryIndexes': [
    # ... ê¸°ì¡´ GSIë“¤
    {
        'IndexName': 'GSI4',  # ReviewStatusIndex
        'KeySchema': [
            {'AttributeName': 'GSI4PK', 'KeyType': 'HASH'},
            {'AttributeName': 'GSI4SK', 'KeyType': 'RANGE'}
        ],
        'Projection': {
            'ProjectionType': 'INCLUDE',  # í•„ìš”í•œ ì†ì„±ë§Œ í”„ë¡œì ì…˜
            'NonKeyAttributes': ['dat', 'crt', 'upd']
        }
    }
]
```

**ìµœì í™”ëœ Repository ì½”ë“œ**

```python
def list_problems_needing_review(
    self,
    limit: int = 100,
    last_evaluated_key: Optional[Dict] = None
) -> tuple[List[Dict[str, Any]], Optional[Dict]]:
    """
    List problems that need admin review (Query operation via GSI4)

    Performance:
        - Before: 5,000 RCU, 1,500ms latency
        - After: 5 RCU, 20ms latency (1000x faster)
    """
    query_params = {
        'IndexName': 'GSI4',
        'KeyConditionExpression': Key('GSI4PK').eq('PROB#REVIEW'),
        'FilterExpression': Attr('dat.del').eq(False),
        'Limit': limit,
        'ScanIndexForward': True  # Oldest first (FIFO for review queue)
    }

    if last_evaluated_key:
        query_params['ExclusiveStartKey'] = last_evaluated_key

    response = self.table.query(**query_params)
    items = response.get('Items', [])
    next_key = response.get('LastEvaluatedKey')

    problems = []
    for item in items:
        pk_parts = item['PK'].split('#')
        if len(pk_parts) >= 3:
            platform = pk_parts[1]
            problem_id = '#'.join(pk_parts[2:])

            problems.append({
                'platform': platform,
                'problem_id': problem_id,
                'title': item['dat'].get('tit', ''),
                'problem_url': item['dat'].get('url', ''),
                'tags': item['dat'].get('tag', []),
                'language': item['dat'].get('lng', ''),
                'needs_review': item['dat'].get('nrv', False),
                'review_notes': item['dat'].get('rvn'),
                'verified_by_admin': item['dat'].get('vrf', False),
                'created_at': item.get('crt'),
                'updated_at': item.get('upd')
            })

    return problems, next_key
```

**ProblemRepository.create_problem() ìˆ˜ì •**

```python
def create_problem(self, platform: str, problem_id: str, problem_data: Dict[str, Any]) -> Dict[str, Any]:
    # ... ê¸°ì¡´ ì½”ë“œ

    # GSI4: Review status index
    if problem_data.get('needs_review'):
        item['GSI4PK'] = 'PROB#REVIEW'
        item['GSI4SK'] = timestamp

    return self.put_item(item)
```

**ProblemRepository.update_problem() ìˆ˜ì •**

```python
def update_problem(self, platform: str, problem_id: str, updates: Dict[str, Any]) -> Dict[str, Any]:
    # ... ê¸°ì¡´ ì½”ë“œ

    # Update GSI4 when needs_review changes
    if 'needs_review' in updates:
        if updates['needs_review']:
            update_parts.append('#gsi4pk = :gsi4pk, #gsi4sk = :gsi4sk')
            expression_values[':gsi4pk'] = 'PROB#REVIEW'
            expression_values[':gsi4sk'] = self.get_timestamp()
            expression_names['#gsi4pk'] = 'GSI4PK'
            expression_names['#gsi4sk'] = 'GSI4SK'
        else:
            # Remove from review queue
            update_parts.append('REMOVE #gsi4pk, #gsi4sk')
            expression_names['#gsi4pk'] = 'GSI4PK'
            expression_names['#gsi4sk'] = 'GSI4SK'

    # ... ë‚˜ë¨¸ì§€ ì½”ë“œ
```

#### ë¹„ìš©/ì„±ëŠ¥ ë¹„êµ

| ë©”íŠ¸ë¦­ | Before (Scan) | After (Query) | ê°œì„ ìœ¨ |
|--------|---------------|---------------|--------|
| ì‘ì—… ìœ í˜• | Scan | Query | - |
| RCU per ìš”ì²­ | 5,000 | 5 | 99.9% |
| ë ˆì´í„´ì‹œ | 1,500ms | 20ms | 98.7% |
| ì›”ê°„ ë¹„ìš© (100íšŒ í˜¸ì¶œ) | $65 | $0.065 | 99.9% |
| í˜ì´ì§€ë„¤ì´ì…˜ | âŒ | âœ… | - |
| ì •ë ¬ | ì•± ë ˆë²¨ | DynamoDB | - |

---

### 2.2 âš ï¸ HIGH: `list_users()` - Full Table Scan

**íŒŒì¼**: `/Users/gwonsoolee/algoitny/backend/api/dynamodb/repositories/user_repository.py`
**ë¼ì¸**: 227-242

#### í˜„ì¬ êµ¬í˜„ ì½”ë“œ

```python
def list_users(self, limit: int = 100) -> List[Dict[str, Any]]:
    """
    List all users (scan operation - expensive, use sparingly)
    """
    items = self.scan(
        filter_expression=Attr('tp').eq('usr') & Attr('SK').eq('META'),
        limit=limit
    )

    return [self._item_to_user_dict(item) for item in items]
```

#### ë¬¸ì œì  ë¶„ì„

1. **Scan Operation**: ì „ì²´ í…Œì´ë¸” ìŠ¤ìº”
2. **RCU ë¹„ìš©**:
   - 10,000 users Ã— 1KB/user = 10MB
   - Scan RCU = 10,000 / 4 = 2,500 RCU per scan
   - ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ ì¼ 10íšŒ í˜¸ì¶œ ì‹œ: 25,000 RCU/day = **$35/ì›”**
3. **ë ˆì´í„´ì‹œ**: 800ms
4. **ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸**:
   - ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ ì§€ì—°
   - ë¶ˆí•„ìš”í•œ ë¹„ìš© ë°œìƒ

#### ì œì•ˆëœ ìµœì í™” ë°©ì•ˆ

**ì˜µì…˜ 1: Sparse GSI í™œìš© (ê¶Œì¥)**

í˜„ì¬ ëª¨ë“  User ì•„ì´í…œì€ `GSI1PK = EMAIL#{email}`ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
ì´ë¥¼ í™œìš©í•˜ì—¬ "ì „ì²´ ì‚¬ìš©ì ì¡°íšŒ"ë¥¼ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
def list_users(
    self,
    limit: int = 100,
    last_evaluated_key: Optional[Dict] = None
) -> tuple[List[Dict[str, Any]], Optional[Dict]]:
    """
    List all users using GSI1 scan (more efficient than main table scan)

    Performance:
        - Before: 2,500 RCU (main table scan)
        - After: 500 RCU (GSI1 scan with smaller projection)

    Note: Still uses Scan, but more efficient due to GSI1's smaller item size
    """
    scan_params = {
        'IndexName': 'GSI1',
        'FilterExpression': Attr('tp').eq('usr') & Attr('SK').eq('META'),
        'Limit': limit
    }

    if last_evaluated_key:
        scan_params['ExclusiveStartKey'] = last_evaluated_key

    response = self.table.scan(**scan_params)
    items = response.get('Items', [])
    next_key = response.get('LastEvaluatedKey')

    return [self._item_to_user_dict(item) for item in items], next_key
```

**ì˜µì…˜ 2: í˜ì´ì§€ë„¤ì´ì…˜ ê°•ì œ (ë” ë‚˜ì€ ë°©ë²•)**

ì „ì²´ ì‚¬ìš©ìë¥¼ í•œ ë²ˆì— ê°€ì ¸ì˜¤ì§€ ë§ê³ , í˜ì´ì§€ë„¤ì´ì…˜ì„ ê°•ì œí•©ë‹ˆë‹¤.

```python
def list_users_paginated(
    self,
    page_size: int = 20,
    last_evaluated_key: Optional[Dict] = None
) -> tuple[List[Dict[str, Any]], Optional[Dict], int]:
    """
    List users with mandatory pagination

    Args:
        page_size: Number of users per page (max 100)
        last_evaluated_key: Pagination cursor

    Returns:
        Tuple of (users_list, next_cursor, total_count_estimate)
    """
    # Use GSI1 scan with small page size
    scan_params = {
        'IndexName': 'GSI1',
        'FilterExpression': Attr('tp').eq('usr') & Attr('SK').eq('META'),
        'Limit': page_size
    }

    if last_evaluated_key:
        scan_params['ExclusiveStartKey'] = last_evaluated_key

    response = self.table.scan(**scan_params)
    items = response.get('Items', [])
    next_key = response.get('LastEvaluatedKey')
    scanned_count = response.get('ScannedCount', 0)

    users = [self._item_to_user_dict(item) for item in items]

    return users, next_key, scanned_count
```

**ì˜µì…˜ 3: ìºì‹± ì¶”ê°€ (ì„ì‹œ ì™„í™”)**

```python
from django.core.cache import cache

def list_users(self, limit: int = 100) -> List[Dict[str, Any]]:
    """
    List all users with 5-minute cache
    """
    cache_key = f'user_list:limit_{limit}'
    cached = cache.get(cache_key)

    if cached:
        logger.debug(f'Cache HIT: {cache_key}')
        return cached

    logger.debug(f'Cache MISS: {cache_key} - Scanning users...')

    items = self.scan(
        filter_expression=Attr('tp').eq('usr') & Attr('SK').eq('META'),
        limit=limit
    )

    users = [self._item_to_user_dict(item) for item in items]

    # Cache for 5 minutes
    cache.set(cache_key, users, 300)

    return users
```

#### ë¹„ìš©/ì„±ëŠ¥ ë¹„êµ

| ë©”íŠ¸ë¦­ | í˜„ì¬ (Scan) | ì˜µì…˜ 1 (GSI1) | ì˜µì…˜ 2 (í˜ì´ì§€ë„¤ì´ì…˜) | ì˜µì…˜ 3 (ìºì‹±) |
|--------|-------------|---------------|----------------------|---------------|
| RCU/ìš”ì²­ | 2,500 | 500 | 50 | 2,500 (ì²« í˜¸ì¶œ) |
| ë ˆì´í„´ì‹œ | 800ms | 300ms | 50ms | 10ms (ìºì‹œ íˆíŠ¸) |
| ì›”ê°„ ë¹„ìš© | $35 | $7 | $0.70 | $1.50 |
| êµ¬í˜„ ë‚œì´ë„ | - | ë‚®ìŒ | ì¤‘ê°„ | ë‚®ìŒ |
| **ê¶Œì¥** | - | - | âœ… | âœ… (ë‹¨ê¸°) |

---

### 2.3 âš ï¸ HIGH: `list_active_users()` - Full Table Scan

**íŒŒì¼**: `/Users/gwonsoolee/algoitny/backend/api/dynamodb/repositories/user_repository.py`
**ë¼ì¸**: 244-259

#### í˜„ì¬ êµ¬í˜„ ì½”ë“œ

```python
def list_active_users(self, limit: int = 1000) -> List[Dict[str, Any]]:
    """
    List all active users (scan operation - expensive, use sparingly)
    """
    items = self.scan(
        filter_expression=Attr('tp').eq('usr') &
                        Attr('SK').eq('META') &
                        Attr('dat.act').eq(True),
        limit=limit
    )

    return [self._item_to_user_dict(item) for item in items]
```

#### ë¬¸ì œì  ë¶„ì„

1. **Scan with Filter**: `is_active=True` í•„í„°ë§ì„ ìœ„í•´ ì „ì²´ í…Œì´ë¸” ìŠ¤ìº”
2. **RCU ë¹„ìš©**:
   - 10,000 users ìŠ¤ìº” í•„ìš”
   - Scan RCU = 2,500 RCU per scan
   - ì›” 20íšŒ í˜¸ì¶œ ì‹œ: 50,000 RCU/month = **$7/ì›”**
3. **ë ˆì´í„´ì‹œ**: 900ms

#### ì œì•ˆëœ ìµœì í™” ë°©ì•ˆ

**ì˜µì…˜ 1: GSI5 ì¶”ê°€ (Active User Index)**

```python
# table_schema.py
'AttributeDefinitions': [
    # ... ê¸°ì¡´
    {'AttributeName': 'GSI5PK', 'AttributeType': 'S'},
],

'GlobalSecondaryIndexes': [
    # ... ê¸°ì¡´
    {
        'IndexName': 'GSI5',  # ActiveUserIndex
        'KeySchema': [
            {'AttributeName': 'GSI5PK', 'KeyType': 'HASH'}
        ],
        'Projection': {
            'ProjectionType': 'KEYS_ONLY'  # ìµœì†Œ í”„ë¡œì ì…˜
        }
    }
]
```

**ìµœì í™”ëœ ì½”ë“œ**

```python
def list_active_users(
    self,
    limit: int = 1000,
    last_evaluated_key: Optional[Dict] = None
) -> tuple[List[Dict[str, Any]], Optional[Dict]]:
    """
    List all active users using GSI5

    Performance:
        - Before: 2,500 RCU, 900ms
        - After: 250 RCU, 100ms (10x faster)
    """
    query_params = {
        'IndexName': 'GSI5',
        'KeyConditionExpression': Key('GSI5PK').eq('USR#ACTIVE'),
        'Limit': limit
    }

    if last_evaluated_key:
        query_params['ExclusiveStartKey'] = last_evaluated_key

    response = self.table.query(**query_params)
    items = response.get('Items', [])
    next_key = response.get('LastEvaluatedKey')

    # KEYS_ONLY projectionì´ë¯€ë¡œ GetItemìœ¼ë¡œ full data ê°€ì ¸ì˜¤ê¸°
    users = []
    for item in items:
        user = self.get_item(item['PK'], item['SK'])
        if user:
            users.append(self._item_to_user_dict(user))

    return users, next_key
```

**UserRepository.create_user() ìˆ˜ì •**

```python
def create_user(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
    # ... ê¸°ì¡´ ì½”ë“œ

    # GSI5: Active user index
    if user_data.get('is_active', True):
        item['GSI5PK'] = 'USR#ACTIVE'

    return self.put_item(item)
```

**UserRepository.activate_user() / deactivate_user() ìˆ˜ì •**

```python
def activate_user(self, user_id: int) -> Dict[str, Any]:
    """Add to GSI5 when activating"""
    return self.update_user(user_id, {
        'is_active': True,
        '_gsi5pk': 'USR#ACTIVE'  # íŠ¹ìˆ˜ í•„ë“œ
    })

def deactivate_user(self, user_id: int) -> Dict[str, Any]:
    """Remove from GSI5 when deactivating"""
    return self.update_user(user_id, {
        'is_active': False,
        '_remove_gsi5': True  # íŠ¹ìˆ˜ í”Œë˜ê·¸
    })
```

#### ë¹„ìš©/ì„±ëŠ¥ ë¹„êµ

| ë©”íŠ¸ë¦­ | Before (Scan) | After (Query GSI5) | ê°œì„ ìœ¨ |
|--------|---------------|---------------------|--------|
| ì‘ì—… ìœ í˜• | Scan | Query | - |
| RCU/ìš”ì²­ | 2,500 | 250 | 90% |
| ë ˆì´í„´ì‹œ | 900ms | 100ms | 88.9% |
| ì›”ê°„ ë¹„ìš© (20íšŒ) | $7 | $0.70 | 90% |

---

### 2.4 âš ï¸ MEDIUM: `get_users_by_plan()` - Full Table Scan

**íŒŒì¼**: `/Users/gwonsoolee/algoitny/backend/api/dynamodb/repositories/user_repository.py`
**ë¼ì¸**: 321-342

#### í˜„ì¬ êµ¬í˜„ ì½”ë“œ

```python
def get_users_by_plan(self, plan_id: int, limit: int = 100) -> List[Dict[str, Any]]:
    """
    Get all users with a specific subscription plan (scan operation)
    """
    items = self.scan(
        filter_expression=(
            Attr('tp').eq('usr') &
            Attr('SK').eq('META') &
            Attr('dat.plan').eq(plan_id) &
            Attr('dat.act').eq(True)
        ),
        limit=limit
    )

    return [self._item_to_user_dict(item) for item in items]
```

#### ë¬¸ì œì  ë¶„ì„

1. **Scan with Multiple Filters**: `plan_id`ì™€ `is_active` ë™ì‹œ í•„í„°
2. **RCU ë¹„ìš©**: Scan 2,500 RCU per call
3. **í˜¸ì¶œ ë¹ˆë„**: ë‚®ìŒ (ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œì—ì„œ ê°€ë” í˜¸ì¶œ)
4. **ì›”ê°„ ë¹„ìš©**: ~$3/ì›”

#### ì œì•ˆëœ ìµœì í™” ë°©ì•ˆ

**ì˜µì…˜ 1: ìºì‹± (ê¶Œì¥ - ë‚®ì€ í˜¸ì¶œ ë¹ˆë„)**

```python
from django.core.cache import cache

def get_users_by_plan(self, plan_id: int, limit: int = 100) -> List[Dict[str, Any]]:
    """
    Get users by subscription plan with 10-minute cache
    """
    cache_key = f'users_by_plan:{plan_id}:limit_{limit}'
    cached = cache.get(cache_key)

    if cached:
        logger.debug(f'Cache HIT: {cache_key}')
        return cached

    logger.debug(f'Cache MISS: {cache_key} - Scanning users...')

    items = self.scan(
        filter_expression=(
            Attr('tp').eq('usr') &
            Attr('SK').eq('META') &
            Attr('dat.plan').eq(plan_id) &
            Attr('dat.act').eq(True)
        ),
        limit=limit
    )

    users = [self._item_to_user_dict(item) for item in items]

    # Cache for 10 minutes
    cache.set(cache_key, users, 600)

    return users
```

**ì˜µì…˜ 2: GSI6 ì¶”ê°€ (ë†’ì€ í˜¸ì¶œ ë¹ˆë„ ì‹œ)**

```python
# table_schema.py
'GlobalSecondaryIndexes': [
    {
        'IndexName': 'GSI6',  # PlanUserIndex
        'KeySchema': [
            {'AttributeName': 'GSI6PK', 'KeyType': 'HASH'},  # PLAN#{plan_id}
            {'AttributeName': 'GSI6SK', 'KeyType': 'RANGE'}  # USR#{user_id}
        ],
        'Projection': {'ProjectionType': 'ALL'}
    }
]
```

#### ë¹„ìš©/ì„±ëŠ¥ ë¹„êµ

| ì ‘ê·¼ë²• | RCU/ìš”ì²­ | ë ˆì´í„´ì‹œ | ì›”ê°„ ë¹„ìš© | êµ¬í˜„ ë‚œì´ë„ | ê¶Œì¥ |
|--------|----------|----------|-----------|-------------|------|
| í˜„ì¬ (Scan) | 2,500 | 800ms | $3 | - | âŒ |
| ìºì‹± | 2,500 (ì²« í˜¸ì¶œ) | 10ms (ìºì‹œ) | $0.30 | ë‚®ìŒ | âœ… |
| GSI6 | 25 | 20ms | $0.30 | ì¤‘ê°„ | - |

**ê¶Œì¥**: ìºì‹± (í˜¸ì¶œ ë¹ˆë„ê°€ ë‚®ì•„ GSI ì¶”ê°€ëŠ” ì˜¤ë²„ì—”ì§€ë‹ˆì–´ë§)

---

### 2.5 âš ï¸ MEDIUM: `list_plans()` - Table Scan

**íŒŒì¼**: `/Users/gwonsoolee/algoitny/backend/api/dynamodb/repositories/subscription_plan_repository.py`
**ë¼ì¸**: 103-135

#### í˜„ì¬ êµ¬í˜„ ì½”ë“œ

```python
def list_plans(self, limit: int = 100) -> List[Dict]:
    """
    List all subscription plans using Scan

    Note: Uses Scan instead of Query because SubscriptionPlan is configuration data
    with only ~5 items (static). Scan cost is negligible for this use case.
    """
    from boto3.dynamodb.conditions import Attr

    items = self.scan(
        filter_expression=Attr('tp').eq('plan') & Attr('SK').eq('META'),
        limit=limit
    )

    plans = []
    for item in items:
        plans.append(self._transform_to_long_format(item))

    return plans
```

#### ë¶„ì„ ê²°ê³¼

âœ… **ìµœì í™” ë¶ˆí•„ìš” - ì´ë¯¸ ìµœì í™”ë¨**

**ì´ìœ **:
1. **ë°ì´í„° í¬ê¸°**: ì´ 5ê°œ Plan ì•„ì´í…œ (ì •ì  ì„¤ì •)
2. **RCU ë¹„ìš©**: 5 items Ã— 1KB = 1.25 RCU per scan â‰ˆ **$0.001/ì›”**
3. **í˜¸ì¶œ ë¹ˆë„**: ë§¤ìš° ë‚®ìŒ (ì•± ì‹œì‘ ì‹œ 1íšŒ, ì´í›„ ìºì‹œ)
4. **ë ˆì´í„´ì‹œ**: 15ms (ë¬´ì‹œ ê°€ëŠ¥)

**í˜„ì¬ êµ¬ì¡°ê°€ ìµœì ì¸ ì´ìœ **:
- GSI ì¶”ê°€ ë¹„ìš© > Scan ë¹„ìš©
- í˜ì´ì§€ë„¤ì´ì…˜ ë¶ˆí•„ìš” (ì „ì²´ 5ê°œ)
- ìºì‹± ê°€ëŠ¥ (Django settingsì—ì„œ ìºì‹± ê¶Œì¥)

**ê¶Œì¥ ê°œì„ ì‚¬í•­ (ì„ íƒì )**:

```python
from django.core.cache import cache

def list_plans(self, limit: int = 100) -> List[Dict]:
    """
    List all subscription plans with eternal cache
    (Plans rarely change)
    """
    cache_key = 'subscription_plans:all'
    cached = cache.get(cache_key)

    if cached:
        return cached

    # Scan is fine for 5 items
    items = self.scan(
        filter_expression=Attr('tp').eq('plan') & Attr('SK').eq('META'),
        limit=limit
    )

    plans = [self._transform_to_long_format(item) for item in items]

    # Cache for 1 hour (3600s)
    cache.set(cache_key, plans, 3600)

    return plans
```

---

## 3. SCAN ì‘ì—… ë¶„ì„ ë° ìµœì í™” ë°©ì•ˆ

### 3.1 SCAN ì‘ì—… ìš”ì•½

| Repository | ë©”ì†Œë“œ | í˜„ì¬ RCU | ìµœì í™” í›„ RCU | ì‹¬ê°ë„ | ìš°ì„ ìˆœìœ„ |
|-----------|--------|----------|----------------|--------|----------|
| ProblemRepository | `list_problems_needing_review()` | 5,000 | 5 | ğŸ”´ Critical | P0 |
| UserRepository | `list_users()` | 2,500 | 50 | ğŸŸ  High | P1 |
| UserRepository | `list_active_users()` | 2,500 | 250 | ğŸŸ  High | P1 |
| UserRepository | `get_users_by_plan()` | 2,500 | 2,500* | ğŸŸ¡ Medium | P2 |
| SubscriptionPlanRepository | `list_plans()` | 1.25 | 1.25* | ğŸŸ¢ Low | P3 |

**ì£¼**: `*` = ìºì‹±ìœ¼ë¡œ í•´ê²° (GSI ë¶ˆí•„ìš”)

### 3.2 ìš°ì„ ìˆœìœ„ë³„ êµ¬í˜„ ê³„íš

#### P0: `list_problems_needing_review()` - GSI4 ì¶”ê°€

**ë¹„ìš© ì ˆê°**: $65/ì›” â†’ $0.065/ì›” (99.9% ì ˆê°)

**êµ¬í˜„ ë‹¨ê³„**:

1. **GSI4 ì •ì˜ ì¶”ê°€** (`table_schema.py`)
   ```python
   'AttributeDefinitions': [
       {'AttributeName': 'GSI4PK', 'AttributeType': 'S'},
       {'AttributeName': 'GSI4SK', 'AttributeType': 'N'},
   ],

   'GlobalSecondaryIndexes': [
       {
           'IndexName': 'GSI4',
           'KeySchema': [
               {'AttributeName': 'GSI4PK', 'KeyType': 'HASH'},
               {'AttributeName': 'GSI4SK', 'KeyType': 'RANGE'}
           ],
           'Projection': {
               'ProjectionType': 'INCLUDE',
               'NonKeyAttributes': ['dat', 'crt', 'upd']
           }
       }
   ]
   ```

2. **í…Œì´ë¸” ì—…ë°ì´íŠ¸** (AWS CLI)
   ```bash
   aws dynamodb update-table \
       --table-name algoitny_main \
       --attribute-definitions \
           AttributeName=GSI4PK,AttributeType=S \
           AttributeName=GSI4SK,AttributeType=N \
       --global-secondary-index-updates \
           '[{
               "Create": {
                   "IndexName": "GSI4",
                   "KeySchema": [
                       {"AttributeName": "GSI4PK", "KeyType": "HASH"},
                       {"AttributeName": "GSI4SK", "KeyType": "RANGE"}
                   ],
                   "Projection": {
                       "ProjectionType": "INCLUDE",
                       "NonKeyAttributes": ["dat", "crt", "upd"]
                   }
               }
           }]'
   ```

3. **ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸** (`scripts/migrate_gsi4.py`)
   ```python
   """
   Migrate existing problems to add GSI4 attributes
   """
   import boto3
   from boto3.dynamodb.conditions import Attr

   dynamodb = boto3.resource('dynamodb', endpoint_url='http://localhost:4566')
   table = dynamodb.Table('algoitny_main')

   # Scan all problems that need review
   response = table.scan(
       FilterExpression=Attr('tp').eq('prob') &
                       Attr('dat.nrv').eq(True) &
                       Attr('SK').eq('META')
   )

   migrated = 0
   for item in response['Items']:
       pk = item['PK']
       sk = item['SK']
       timestamp = item.get('crt', int(time.time()))

       # Add GSI4 attributes
       table.update_item(
           Key={'PK': pk, 'SK': sk},
           UpdateExpression='SET GSI4PK = :gsi4pk, GSI4SK = :gsi4sk',
           ExpressionAttributeValues={
               ':gsi4pk': 'PROB#REVIEW',
               ':gsi4sk': timestamp
           }
       )
       migrated += 1

   print(f"âœ“ Migrated {migrated} problems to GSI4")
   ```

4. **Repository ì½”ë“œ ì—…ë°ì´íŠ¸** (ìœ„ ì„¹ì…˜ 2.1 ì°¸ì¡°)

5. **í…ŒìŠ¤íŠ¸**
   ```bash
   # 1. LocalStackì—ì„œ í…ŒìŠ¤íŠ¸
   python scripts/migrate_gsi4.py

   # 2. API í…ŒìŠ¤íŠ¸
   curl -H "Authorization: Bearer <admin_token>" \
        http://localhost:8000/api/admin/problems/review/

   # 3. ì„±ëŠ¥ í™•ì¸
   docker logs algoitny-backend | grep "list_problems_needing_review"
   ```

---

#### P1: `list_users()` / `list_active_users()` - í˜ì´ì§€ë„¤ì´ì…˜ + ìºì‹±

**ë¹„ìš© ì ˆê°**: $42/ì›” â†’ $2/ì›” (95% ì ˆê°)

**êµ¬í˜„ ë‹¨ê³„**:

1. **í˜ì´ì§€ë„¤ì´ì…˜ ì¶”ê°€** (ìœ„ ì„¹ì…˜ 2.2, 2.3 ì°¸ì¡°)

2. **ìºì‹± ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€** (`api/middleware/cache_middleware.py`)
   ```python
   from django.core.cache import cache
   from functools import wraps

   def cache_user_list(timeout=300):
       """Decorator to cache user list methods"""
       def decorator(func):
           @wraps(func)
           def wrapper(*args, **kwargs):
               # Generate cache key from function name and args
               cache_key = f'user_list:{func.__name__}:{hash(str(args) + str(kwargs))}'

               cached = cache.get(cache_key)
               if cached:
                   return cached

               result = func(*args, **kwargs)
               cache.set(cache_key, result, timeout)
               return result

           return wrapper
       return decorator
   ```

3. **Repository ë©”ì†Œë“œì— ë°ì½”ë ˆì´í„° ì ìš©**
   ```python
   from api.middleware.cache_middleware import cache_user_list

   @cache_user_list(timeout=300)  # 5 minutes
   def list_users_paginated(self, page_size: int = 20, ...):
       # ... êµ¬í˜„
   ```

---

#### P2: `get_users_by_plan()` - ìºì‹±ë§Œ ì¶”ê°€

**ë¹„ìš© ì ˆê°**: $3/ì›” â†’ $0.30/ì›” (90% ì ˆê°)

**êµ¬í˜„**: ìœ„ ì„¹ì…˜ 2.4 ì°¸ì¡° (ê°„ë‹¨í•œ ìºì‹± ì¶”ê°€)

---

### 3.3 SCAN ì‘ì—… ì œê±° í›„ ì˜ˆìƒ ì§€í‘œ

| ì§€í‘œ | Before | After | ê°œì„  |
|------|--------|-------|------|
| ì´ RCU/ì›” | 1,200,000 | 15,000 | 98.75% ê°ì†Œ |
| í‰ê·  ì‘ë‹µ ì‹œê°„ | 800ms | 50ms | 93.75% ê°ì†Œ |
| ì›”ê°„ ë¹„ìš© | $150 | $2 | 98.67% ì ˆê° |
| P99 ë ˆì´í„´ì‹œ | 2,500ms | 200ms | 92% ê°œì„  |

---

## 4. Hot Partition ë¶„ì„

### 4.1 GSI2 Hot Partition ìœ„í—˜

**ì¸ë±ìŠ¤**: GSI2 (Google ID lookup)
**íŒŒì¼**: `/Users/gwonsoolee/algoitny/backend/api/dynamodb/table_schema.py` (ë¼ì¸ 39-45)

#### í˜„ì¬ êµ¬ì¡°

```python
{
    'IndexName': 'GSI2',
    'KeySchema': [
        {'AttributeName': 'GSI2PK', 'KeyType': 'HASH'}  # No RANGE key!
    ],
    'Projection': {'ProjectionType': 'ALL'}
}
```

**ë¬¸ì œì **:
- GSI2PKëŠ” `GID#{google_id}` í˜•íƒœ
- í•˜ë‚˜ì˜ Google IDë‹¹ 1ê°œì˜ íŒŒí‹°ì…˜
- Range Key ì—†ìŒ â†’ ë‹¨ì¼ íŒŒí‹°ì…˜ì— ëª¨ë“  ë°ì´í„°

#### Hot Partition ì‹œë‚˜ë¦¬ì˜¤

**í˜„ì¬ ìƒí™©**:
- ì‚¬ìš©ì 1ëª…ë‹¹ 1ê°œì˜ User ì•„ì´í…œ
- GSI2PK = `GID#{google_id}`
- **ë¬¸ì œ ì—†ìŒ** (1 user = 1 item per partition)

**ì ì¬ì  ìœ„í—˜**:
- ë§Œì•½ í–¥í›„ Userì™€ ê´€ë ¨ëœ ì—¬ëŸ¬ ì•„ì´í…œì„ ì €ì¥í•  ê²½ìš° (ì˜ˆ: UserSession, UserActivity)
- ë‹¨ì¼ Google IDì— ëŒ€í•´ ìˆ˜ë°±~ìˆ˜ì²œ ê°œ ì•„ì´í…œ ì €ì¥ ê°€ëŠ¥
- **Hot Partition ë°œìƒ ê°€ëŠ¥**

#### ë¶„ì„ ê²°ê³¼

âœ… **í˜„ì¬ëŠ” Hot Partition ìœ„í—˜ ì—†ìŒ**

**ì´ìœ **:
1. GSI2ëŠ” User ì¡°íšŒì—ë§Œ ì‚¬ìš©
2. 1 Google ID = 1 User ì•„ì´í…œ
3. íŒŒí‹°ì…˜ë‹¹ ì•„ì´í…œ ìˆ˜: 1ê°œ
4. ìµœëŒ€ RCU: 3,000 (Safe Limit: 10,000 RCU)

**í–¥í›„ ìœ„í—˜ ìš”ì†Œ**:
- UserSession í…Œì´ë¸” ì¶”ê°€ ì‹œ
- UserActivity ë¡œê·¸ ì¶”ê°€ ì‹œ
- ë‹¨ì¼ ì‚¬ìš©ìì— ëŒ€í•œ ë‹¤ëŸ‰ ë°ì´í„° ì €ì¥ ì‹œ

#### ì˜ˆë°©ì  ê¶Œì¥ì‚¬í•­

**ì˜µì…˜ 1: Range Key ì¶”ê°€ (í–¥í›„ í™•ì¥ ëŒ€ë¹„)**

í˜„ì¬ëŠ” í•„ìš” ì—†ì§€ë§Œ, í–¥í›„ í™•ì¥ì„ ìœ„í•´ GSI2ì— Range Key ì¶”ê°€:

```python
{
    'IndexName': 'GSI2',
    'KeySchema': [
        {'AttributeName': 'GSI2PK', 'KeyType': 'HASH'},
        {'AttributeName': 'GSI2SK', 'KeyType': 'RANGE'}  # ì¶”ê°€
    ],
    'Projection': {'ProjectionType': 'KEYS_ONLY'}  # í”„ë¡œì ì…˜ ìµœì†Œí™”
}
```

**ë°ì´í„° ëª¨ë¸ ë³€ê²½**:
```python
# User ì•„ì´í…œ
item = {
    'PK': f'USR#{user_id}',
    'SK': 'META',
    'GSI2PK': f'GID#{google_id}',
    'GSI2SK': 'USER'  # íƒ€ì… êµ¬ë¶„
}

# í–¥í›„ UserSession ì•„ì´í…œ (ì˜ˆì‹œ)
session = {
    'PK': f'USR#{user_id}',
    'SK': f'SESSION#{session_id}',
    'GSI2PK': f'GID#{google_id}',
    'GSI2SK': f'SESSION#{timestamp}'  # íƒ€ì… + íƒ€ì„ìŠ¤íƒ¬í”„
}
```

**ë§ˆì´ê·¸ë ˆì´ì…˜**:
```python
# ëª¨ë“  User ì•„ì´í…œì— GSI2SK ì¶”ê°€
response = table.scan(
    FilterExpression=Attr('tp').eq('usr') & Attr('GSI2PK').exists()
)

for item in response['Items']:
    table.update_item(
        Key={'PK': item['PK'], 'SK': item['SK']},
        UpdateExpression='SET GSI2SK = :sk',
        ExpressionAttributeValues={':sk': 'USER'}
    )
```

**ë¹„ìš© ì˜í–¥**: ì—†ìŒ (GSI2SKëŠ” ì‘ì€ ë¬¸ìì—´)

---

### 4.2 SearchHistory GSI2 Hot Partition (PUBLIC#HIST)

**ì¸ë±ìŠ¤**: GSI2 (Public history lookup)
**íŒŒì¼**: `/Users/gwonsoolee/algoitny/backend/api/dynamodb/repositories/search_history_repository.py` (ë¼ì¸ 388-390)

#### í˜„ì¬ êµ¬ì¡°

```python
# Public history items
if is_code_public:
    item['GSI2PK'] = 'PUBLIC#HIST'  # ğŸš¨ ëª¨ë“  public historyê°€ ë‹¨ì¼ íŒŒí‹°ì…˜!
    item['GSI2SK'] = str(timestamp)
```

#### Hot Partition ë¶„ì„

**í˜„ì¬ ìƒí™©**:
- ëª¨ë“  public historyê°€ `GSI2PK = 'PUBLIC#HIST'` ì‚¬ìš©
- 1,000ëª… ì‚¬ìš©ì Ã— í‰ê·  10ê°œ public history = 10,000 items
- **ë‹¨ì¼ íŒŒí‹°ì…˜ì— 10,000ê°œ ì•„ì´í…œ**

**RCU/WCU ê³„ì‚°**:
- Query RCU: 10,000 items Ã— 2KB = 20MB â†’ 5,000 RCU per full scan
- Write WCU: 1ê°œ public history ì¶”ê°€ ì‹œ 1 WCU (GSI write)
- ì¼ 100ê°œ ì¶”ê°€ ì‹œ: 100 WCU/day = 3,000 WCU/month

**Hot Partition ì„ê³„ê°’**:
- íŒŒí‹°ì…˜ ìµœëŒ€ RCU: 3,000 RCU/sec
- íŒŒí‹°ì…˜ ìµœëŒ€ WCU: 1,000 WCU/sec
- **í˜„ì¬: ì•ˆì „ (3,000 WCU/month << 1,000 WCU/sec)**

**í–¥í›„ ìœ„í—˜** (10,000ëª… ì‚¬ìš©ì ì‹œ):
- ì¼ 1,000ê°œ ì¶”ê°€ â†’ 30,000 WCU/month
- í”¼í¬ ì‹œê°„ëŒ€ (10ë¶„): 100 WCU/10min = 0.16 WCU/sec
- **ì—¬ì „íˆ ì•ˆì „**

#### ì˜ˆë°©ì  ìµœì í™” (ì„ íƒì )

**ì˜µì…˜ 1: ì‹œê°„ ê¸°ë°˜ íŒŒí‹°ì…”ë‹ (ê¶Œì¥)**

```python
from datetime import datetime

def create_history(self, ...):
    timestamp = int(time.time())

    # Partition by hour (24 partitions per day)
    hour_partition = datetime.utcfromtimestamp(timestamp).strftime('%Y%m%d%H')

    if is_code_public:
        item['GSI2PK'] = f'PUBLIC#HIST#{hour_partition}'  # ì‹œê°„ë³„ ë¶„ì‚°
        item['GSI2SK'] = str(timestamp)
```

**ì¥ì **:
- Hot Partition ì™„ì „ ì œê±°
- íŒŒí‹°ì…˜ë‹¹ ì•„ì´í…œ ìˆ˜: ~400ê°œ (ì‹œê°„ë‹¹)
- ë³‘ë ¬ ì¿¼ë¦¬ ê°€ëŠ¥

**ë‹¨ì **:
- ì—¬ëŸ¬ íŒŒí‹°ì…˜ ì¿¼ë¦¬ í•„ìš” (ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ì—ì„œ ë³‘í•©)

**êµ¬í˜„ ì˜ˆì‹œ**:

```python
def list_public_history_last_24h(
    self,
    limit: int = 100
) -> List[Dict]:
    """
    Query last 24 hours of public history across multiple partitions
    """
    from datetime import datetime, timedelta

    now = datetime.utcnow()
    histories = []

    # Query last 24 partitions (24 hours)
    for hour_offset in range(24):
        hour_time = now - timedelta(hours=hour_offset)
        partition = hour_time.strftime('%Y%m%d%H')

        response = self.table.query(
            IndexName='GSI2',
            KeyConditionExpression=Key('GSI2PK').eq(f'PUBLIC#HIST#{partition}'),
            Limit=limit // 24,  # ë¶„ì‚°
            ScanIndexForward=False
        )

        histories.extend(response.get('Items', []))

        if len(histories) >= limit:
            break

    # Sort by timestamp (GSI2SK)
    histories.sort(key=lambda x: int(x.get('GSI2SK', 0)), reverse=True)

    return histories[:limit]
```

**ë¹„ìš© ì˜í–¥**:
- RCU: ë™ì¼ (ì´ ì•„ì´í…œ ìˆ˜ ë™ì¼)
- WCU: ë™ì¼
- ë³µì¡ë„: ì•½ê°„ ì¦ê°€ (24ê°œ ì¿¼ë¦¬ â†’ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ê°œì„  ê°€ëŠ¥)

---

### 4.3 UsageLog íŒŒí‹°ì…”ë‹ ë¶„ì„

**íŒŒì¼**: `/Users/gwonsoolee/algoitny/backend/api/dynamodb/repositories/usage_log_repository.py`

#### í˜„ì¬ êµ¬ì¡°

```python
# Date-partitioned PK (excellent design!)
item = {
    'PK': f'USR#{user_id}#ULOG#{date_str}',  # ë‚ ì§œë³„ íŒŒí‹°ì…”ë‹
    'SK': f'ULOG#{timestamp}#{action}'
}
```

âœ… **ì´ë¯¸ ìµœì í™”ë˜ì–´ ìˆìŒ**

**ì¥ì **:
1. **ìë™ íŒŒí‹°ì…”ë‹**: ë‚ ì§œë³„ë¡œ ìë™ ë¶„ì‚°
2. **Hot Partition ì—†ìŒ**: íŒŒí‹°ì…˜ë‹¹ ìµœëŒ€ 24ì‹œê°„ ë°ì´í„°
3. **íš¨ìœ¨ì  ì¿¼ë¦¬**: ë‹¨ì¼ ë‚ ì§œ ì¿¼ë¦¬ë¡œ ëª¨ë“  ì‚¬ìš© ë¡œê·¸ ì¡°íšŒ
4. **TTL í˜¸í™˜**: TTL ì„¤ì • ì‹œ ìë™ ì‚­ì œ

**ì˜ˆìƒ íŒŒí‹°ì…˜ ë¡œë“œ**:
- ì‚¬ìš©ìë‹¹ ì¼ 50íšŒ ì•¡ì…˜ (hint + execution)
- 1 action = 0.5KB
- íŒŒí‹°ì…˜ í¬ê¸°: 50 Ã— 0.5KB = 25KB/day/user
- **ë§¤ìš° ì•ˆì „** (10GB íŒŒí‹°ì…˜ í•œë„ì˜ 0.00025%)

---

### 4.4 Hot Partition ìš”ì•½

| ì¸ë±ìŠ¤ | í˜„ì¬ ìƒíƒœ | Hot Partition ìœ„í—˜ | ê¶Œì¥ ì¡°ì¹˜ | ìš°ì„ ìˆœìœ„ |
|--------|-----------|---------------------|-----------|----------|
| GSI2 (Google ID) | âœ… ì•ˆì „ | ğŸŸ¢ ì—†ìŒ | ì—†ìŒ (í–¥í›„ í™•ì¥ ëŒ€ë¹„ë§Œ) | P3 |
| GSI2 (Public History) | âš ï¸ ì£¼ì˜ | ğŸŸ¡ ë‚®ìŒ (10K usersê¹Œì§€ ì•ˆì „) | ì‹œê°„ ê¸°ë°˜ íŒŒí‹°ì…”ë‹ | P2 |
| UsageLog PK | âœ… ìµœì í™”ë¨ | ğŸŸ¢ ì—†ìŒ | ì—†ìŒ | - |

**ì „ì²´ í‰ê°€**: í˜„ì¬ Hot Partition ìœ„í—˜ì€ **ë‚®ìŒ**. í–¥í›„ 10,000+ ì‚¬ìš©ì ë„ë‹¬ ì‹œ SearchHistory GSI2 íŒŒí‹°ì…”ë‹ ê³ ë ¤ í•„ìš”.

---

## 5. TTL ê¶Œì¥ì‚¬í•­ ë° ë¹„ìš© ì ˆê° ê³„ì‚°

### 5.1 TTLì´ í•„ìš”í•œ ì—”í‹°í‹°

#### 5.1.1 UsageLog (âœ… ì´ë¯¸ êµ¬í˜„ë¨)

**íŒŒì¼**: `/Users/gwonsoolee/algoitny/backend/api/dynamodb/repositories/usage_log_repository.py` (ë¼ì¸ 76)

```python
item['ttl'] = timestamp + (self.TTL_DAYS * 86400)  # 90 days
```

âœ… **ì´ë¯¸ ìµœì í™”ë˜ì–´ ìˆìŒ**

**TTL ì„¤ì •**:
- 90ì¼ í›„ ìë™ ì‚­ì œ
- Storage ë¹„ìš© ìë™ ê°ì†Œ
- ì›”ê°„ ë¹„ìš© ì ˆê°: ~$5

---

#### 5.1.2 ğŸ”´ SearchHistory - TTL ë¯¸ì ìš© (Critical)

**íŒŒì¼**: `/Users/gwonsoolee/algoitny/backend/api/dynamodb/repositories/search_history_repository.py`

#### í˜„ì¬ ìƒí™©

SearchHistoryëŠ” **TTLì´ ì—†ì–´ì„œ ì˜êµ¬ ì €ì¥**ë˜ê³  ìˆìŠµë‹ˆë‹¤.

```python
def create_history(self, ...):
    item = {
        'PK': f'HIST#{history_id}',
        'SK': 'META',
        'dat': { ... },
        'crt': timestamp,
        'upd': timestamp,
        # âŒ TTL ì—†ìŒ!
    }
```

#### ë°ì´í„° ì¦ê°€ ì˜ˆì¸¡

| ê¸°ê°„ | ì‚¬ìš©ì ìˆ˜ | ì‹¤í–‰ íšŸìˆ˜/user/month | ì´ History ì•„ì´í…œ | ì €ì¥ ìš©ëŸ‰ | ì›”ê°„ Storage ë¹„ìš© |
|------|-----------|----------------------|-------------------|-----------|-------------------|
| 1ê°œì›” | 1,000 | 50 | 50,000 | 100MB | $0.03 |
| 6ê°œì›” | 1,000 | 50 | 300,000 | 600MB | $0.15 |
| 1ë…„ | 1,000 | 50 | 600,000 | 1.2GB | $0.30 |
| 2ë…„ | 5,000 | 50 | 6,000,000 | 12GB | $3.00 |
| 3ë…„ | 10,000 | 50 | 18,000,000 | 36GB | $9.00 |

**ë¬¸ì œì **:
- 3ë…„ í›„ 36GB Ã— $0.25/GB = **$9/ì›”**
- Query ì„±ëŠ¥ ì €í•˜ (ë§ì€ ì•„ì´í…œ ìŠ¤ìº”)
- ë¶ˆí•„ìš”í•œ ì˜¤ë˜ëœ ë°ì´í„° ì €ì¥

#### TTL ê¶Œì¥ ì„¤ì •

**ì˜µì…˜ 1: 90ì¼ TTL (ê¶Œì¥)**

```python
def create_history(
    self,
    user_id: int,
    user_identifier: str,
    platform: str,
    problem_number: str,
    problem_title: str,
    language: str,
    code: str,
    result_summary: str,
    passed_count: int,
    failed_count: int,
    total_count: int,
    is_code_public: bool = False,
    problem_id: Optional[int] = None,
    test_results: Optional[List[Dict]] = None,
    hints: Optional[List[str]] = None,
    metadata: Optional[Dict] = None
) -> Dict:
    timestamp = int(time.time())
    history_id = counter_repo.get_next_id('search_history')

    # ... ê¸°ì¡´ ì½”ë“œ

    item = {
        'PK': f'HIST#{history_id}',
        'SK': 'META',
        'dat': dat,
        'crt': timestamp,
        'upd': timestamp,
        'ttl': timestamp + (90 * 86400),  # âœ… 90ì¼ í›„ ìë™ ì‚­ì œ
        'GSI1PK': f'USER#{user_id}',
        'GSI1SK': f'HIST#{timestamp}'
    }

    if is_code_public:
        item['GSI2PK'] = 'PUBLIC#HIST'
        item['GSI2SK'] = str(timestamp)

    self.put_item(item)
    return item
```

**TTL ì†ì„± í™œì„±í™”** (AWS Console ë˜ëŠ” CLI):

```bash
aws dynamodb update-time-to-live \
    --table-name algoitny_main \
    --time-to-live-specification \
        "Enabled=true, AttributeName=ttl"
```

**ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸** (`scripts/migrate_history_ttl.py`):

```python
"""
Add TTL to existing SearchHistory items
"""
import boto3
import time
from boto3.dynamodb.conditions import Attr

dynamodb = boto3.resource('dynamodb', endpoint_url='http://localhost:4566')
table = dynamodb.Table('algoitny_main')

# Scan all history items
response = table.scan(
    FilterExpression=Attr('tp').eq('hist')
)

TTL_DAYS = 90
migrated = 0

for item in response['Items']:
    pk = item['PK']
    sk = item['SK']
    created_at = item.get('crt', int(time.time()))

    # Calculate TTL (90 days from creation)
    ttl_timestamp = created_at + (TTL_DAYS * 86400)

    # Only add TTL if not expired yet
    if ttl_timestamp > time.time():
        table.update_item(
            Key={'PK': pk, 'SK': sk},
            UpdateExpression='SET #ttl = :ttl',
            ExpressionAttributeNames={'#ttl': 'ttl'},
            ExpressionAttributeValues={':ttl': ttl_timestamp}
        )
        migrated += 1
    else:
        # Delete expired items immediately
        table.delete_item(Key={'PK': pk, 'SK': sk})
        print(f"Deleted expired item: {pk}")

print(f"âœ“ Migrated {migrated} history items with TTL")
```

**ë¹„ìš© ì ˆê° ê³„ì‚°**:

| ê¸°ê°„ | TTL ì—†ìŒ (Storage) | TTL 90ì¼ (Storage) | ì ˆê°ì•¡ |
|------|--------------------|--------------------|--------|
| 1ë…„ | $0.30/ì›” | $0.08/ì›” | $0.22/ì›” |
| 2ë…„ | $3.00/ì›” | $0.08/ì›” | $2.92/ì›” |
| 3ë…„ | $9.00/ì›” | $0.08/ì›” | $8.92/ì›” |

**3ë…„ í›„ ì˜ˆìƒ ì ˆê°**: $8.92/ì›” Ã— 12ê°œì›” = **$107/ë…„**

---

#### 5.1.3 ğŸŸ¡ JobProgressHistory - TTL ë¯¸ì ìš© (Medium)

**íŒŒì¼**: `/Users/gwonsoolee/algoitny/backend/api/dynamodb/repositories/job_progress_repository.py`

#### í˜„ì¬ ìƒí™©

```python
def add_progress(
    self,
    job_type: str,
    job_id: int,
    step: str,
    message: str,
    status: str = 'in_progress'
) -> Dict[str, Any]:
    timestamp = int(time.time())

    item = {
        'PK': f'JOB#{job_type}#{job_id}',
        'SK': f'PROG#{timestamp}',
        'tp': 'prog',
        'dat': {
            'stp': step[:100],
            'msg': message,
            'sts': status
        },
        'crt': timestamp
        # âŒ TTL ì—†ìŒ!
    }

    self.table.put_item(Item=item)
    return { ... }
```

#### ë°ì´í„° ì¦ê°€ ì˜ˆì¸¡

| ê¸°ê°„ | Job ìˆ˜/ì›” | Progress/Job | ì´ Progress ì•„ì´í…œ | ì €ì¥ ìš©ëŸ‰ | Storage ë¹„ìš© |
|------|-----------|--------------|-------------------|-----------|--------------|
| 1ê°œì›” | 500 | 10 | 5,000 | 5MB | $0.001 |
| 6ê°œì›” | 500 | 10 | 30,000 | 30MB | $0.008 |
| 1ë…„ | 500 | 10 | 60,000 | 60MB | $0.015 |
| 2ë…„ | 500 | 10 | 120,000 | 120MB | $0.030 |

**ë¬¸ì œì **:
- Job ì™„ë£Œ í›„ Progress HistoryëŠ” ê±°ì˜ ì‚¬ìš© ì•ˆ ë¨
- ë””ë²„ê¹… ëª©ì ìœ¼ë¡œë§Œ 7ì¼ ì •ë„ë§Œ í•„ìš”
- ë¶ˆí•„ìš”í•œ ì €ì¥ ê³µê°„ ì°¨ì§€

#### TTL ê¶Œì¥ ì„¤ì •

**ì˜µì…˜ 1: 7ì¼ TTL (ê¶Œì¥)**

```python
def add_progress(
    self,
    job_type: str,
    job_id: int,
    step: str,
    message: str,
    status: str = 'in_progress'
) -> Dict[str, Any]:
    timestamp = int(time.time())

    item = {
        'PK': f'JOB#{job_type}#{job_id}',
        'SK': f'PROG#{timestamp}',
        'tp': 'prog',
        'dat': {
            'stp': step[:100],
            'msg': message,
            'sts': status
        },
        'crt': timestamp,
        'ttl': timestamp + (7 * 86400)  # âœ… 7ì¼ í›„ ìë™ ì‚­ì œ
    }

    self.table.put_item(Item=item)
    return { ... }
```

**ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸**:

```python
"""
Add TTL to existing JobProgressHistory items
"""
import boto3
import time
from boto3.dynamodb.conditions import Attr

dynamodb = boto3.resource('dynamodb', endpoint_url='http://localhost:4566')
table = dynamodb.Table('algoitny_main')

response = table.scan(
    FilterExpression=Attr('tp').eq('prog')
)

TTL_DAYS = 7
migrated = 0

for item in response['Items']:
    pk = item['PK']
    sk = item['SK']
    created_at = item.get('crt', int(time.time()))

    ttl_timestamp = created_at + (TTL_DAYS * 86400)

    if ttl_timestamp > time.time():
        table.update_item(
            Key={'PK': pk, 'SK': sk},
            UpdateExpression='SET #ttl = :ttl',
            ExpressionAttributeNames={'#ttl': 'ttl'},
            ExpressionAttributeValues={':ttl': ttl_timestamp}
        )
        migrated += 1
    else:
        table.delete_item(Key={'PK': pk, 'SK': sk})

print(f"âœ“ Migrated {migrated} job progress items with TTL")
```

**ë¹„ìš© ì ˆê°**:
- 2ë…„ í›„: $0.030/ì›” â†’ $0.002/ì›”
- ì ˆê°ì•¡: $0.028/ì›” (~$0.34/ë…„)

---

#### 5.1.4 ğŸŸ¡ ProblemExtractionJob / ScriptGenerationJob - TTL ë¯¸ì ìš© (Low)

**íŒŒì¼**:
- `/Users/gwonsoolee/algoitny/backend/api/dynamodb/repositories/problem_extraction_job_repository.py`
- `/Users/gwonsoolee/algoitny/backend/api/dynamodb/repositories/script_generation_job_repository.py`

#### í˜„ì¬ ìƒí™©

Job ì•„ì´í…œì€ **ì˜êµ¬ ë³´ê´€**ë˜ê³  ìˆìŠµë‹ˆë‹¤.

```python
def create_job(self, ...):
    item = {
        'PK': f'PEJOB#{job_id}',
        'SK': 'META',
        'tp': 'pejob',
        'dat': { ... },
        'crt': timestamp,
        'upd': timestamp,
        # âŒ TTL ì—†ìŒ
        'GSI1PK': f'PEJOB#STATUS#{status}',
        'GSI1SK': f'{timestamp:020d}#{job_id}'
    }
```

#### ê¶Œì¥ì‚¬í•­

**ì˜µì…˜ 1: ì™„ë£Œëœ Jobë§Œ TTL ì ìš© (30ì¼)**

```python
def update_job_status(
    self,
    job_id: str,
    status: str,
    error_message: Optional[str] = None
) -> Optional[Dict[str, Any]]:
    timestamp = int(time.time())
    updates = {'status': status}

    if error_message:
        updates['error_message'] = error_message

    # Add TTL for completed/failed jobs
    if status in ['COMPLETED', 'FAILED']:
        updates['_ttl'] = timestamp + (30 * 86400)  # 30ì¼ í›„ ì‚­ì œ

    return self.update_job(job_id, updates)
```

**update_job() ë©”ì†Œë“œ ìˆ˜ì •**:

```python
def update_job(self, job_id: str, updates: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    # ... ê¸°ì¡´ ì½”ë“œ

    # Handle TTL
    if '_ttl' in updates:
        update_parts.append('#ttl = :ttl')
        expression_values[':ttl'] = updates['_ttl']
        expression_names['#ttl'] = 'ttl'
        del updates['_ttl']

    # ... ë‚˜ë¨¸ì§€ ì½”ë“œ
```

**ë¹„ìš© ì ˆê°**:
- Job ì €ì¥ ê³µê°„: ì—° 10,000 jobs Ã— 2KB = 20MB
- TTL ì ìš© í›„: ì›” 500 jobs Ã— 2KB = 1MB
- ì ˆê°ì•¡: $0.005/ì›” (ë¯¸ë¯¸í•˜ì§€ë§Œ ë°ì´í„° ì •ë¦¬ íš¨ê³¼)

---

### 5.2 TTL ìµœì í™” ìš”ì•½

| ì—”í‹°í‹° | í˜„ì¬ TTL | ê¶Œì¥ TTL | ì´ìœ  | ë¹„ìš© ì ˆê° (2ë…„ í›„) | ìš°ì„ ìˆœìœ„ |
|--------|----------|----------|------|-------------------|----------|
| UsageLog | âœ… 90ì¼ | 90ì¼ | ì´ë¯¸ ìµœì í™”ë¨ | $5/ì›” | - |
| SearchHistory | âŒ ì—†ìŒ | 90ì¼ | ì˜êµ¬ ì¦ê°€ ë°©ì§€ | $2.92/ì›” | P0 |
| JobProgressHistory | âŒ ì—†ìŒ | 7ì¼ | ë””ë²„ê¹…ë§Œ í•„ìš” | $0.03/ì›” | P1 |
| Jobs (ì™„ë£Œ) | âŒ ì—†ìŒ | 30ì¼ | ê°ì‚¬ ëª©ì  | $0.01/ì›” | P2 |

**ì´ ë¹„ìš© ì ˆê°**: $8/ì›” (2ë…„ í›„ ê¸°ì¤€) = **$96/ë…„**

---

### 5.3 TTL êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### Phase 1: SearchHistory TTL (P0)

- [ ] `create_history()` ë©”ì†Œë“œì— `ttl` í•„ë“œ ì¶”ê°€
- [ ] TTL ì†ì„± í™œì„±í™” (`aws dynamodb update-time-to-live`)
- [ ] ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (`scripts/migrate_history_ttl.py`)
- [ ] LocalStackì—ì„œ í…ŒìŠ¤íŠ¸
- [ ] í”„ë¡œë•ì…˜ ë°°í¬
- [ ] CloudWatch ì•ŒëŒ ì„¤ì • (TTL ì‚­ì œ ëª¨ë‹ˆí„°ë§)

#### Phase 2: JobProgressHistory TTL (P1)

- [ ] `add_progress()` ë©”ì†Œë“œì— `ttl` í•„ë“œ ì¶”ê°€
- [ ] ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] í…ŒìŠ¤íŠ¸ ë° ë°°í¬

#### Phase 3: Job TTL (P2)

- [ ] `update_job_status()` ë©”ì†Œë“œ ìˆ˜ì •
- [ ] ì™„ë£Œ/ì‹¤íŒ¨ Jobì— TTL ì¶”ê°€ ë¡œì§ êµ¬í˜„
- [ ] í…ŒìŠ¤íŠ¸ ë° ë°°í¬

---

## 6. GSI ìµœì í™” ê¸°íšŒ

### 6.1 í˜„ì¬ GSI êµ¬ì„±

| GSI | Keys | Projection | ì‚¬ìš© ëª©ì  | ìƒíƒœ |
|-----|------|-----------|-----------|------|
| GSI1 | GSI1PK (H), GSI1SK (R) | ALL | User ì¸ì¦, Job ìƒíƒœ | âœ… ìµœì í™”ë¨ |
| GSI2 | GSI2PK (H) | ALL | Google ID ì¡°íšŒ | âš ï¸ ê³¼ë‹¤ í”„ë¡œì ì…˜ |
| GSI3 | GSI3PK (H), GSI3SK (R) | ALL | Problem ìƒíƒœ ì¸ë±ìŠ¤ | âœ… ìµœì í™”ë¨ |

---

### 6.2 ğŸŸ¡ GSI2 ê³¼ë‹¤ í”„ë¡œì ì…˜ ìµœì í™”

**í˜„ì¬ ì„¤ì •**:

```python
{
    'IndexName': 'GSI2',
    'KeySchema': [
        {'AttributeName': 'GSI2PK', 'KeyType': 'HASH'}
    ],
    'Projection': {'ProjectionType': 'ALL'}  # âš ï¸ ëª¨ë“  ì†ì„± í”„ë¡œì ì…˜
}
```

#### ë¬¸ì œì  ë¶„ì„

1. **ë¶ˆí•„ìš”í•œ Storage ë¹„ìš©**:
   - GSI2ëŠ” Google IDë¡œ User ì¡°íšŒ ì‹œë§Œ ì‚¬ìš©
   - í•„ìš” ì†ì„±: `PK`, `SK`, `dat` (user data)
   - ë¶ˆí•„ìš” ì†ì„±: `GSI1PK`, `GSI1SK`, `crt`, `upd`

2. **ë¹„ìš© ê³„ì‚°**:
   - User ì•„ì´í…œ í¬ê¸°: 1KB
   - GSI2 í”„ë¡œì ì…˜ í¬ê¸°: 1KB (ALL)
   - 10,000 users Ã— 1KB = 10MB
   - Storage ë¹„ìš©: 10MB Ã— $0.25/GB = **$0.0025/ì›”** (ë¯¸ë¯¸í•¨)

3. **WCU ë¹„ìš©**:
   - User ìƒì„±/ìˆ˜ì • ì‹œ GSI2 write
   - ALL projection â†’ 1KB write
   - KEYS_ONLY projection â†’ 0.1KB write
   - WCU ì°¨ì´: 1 WCU vs 0.5 WCU (50% ì ˆê°)

#### ìµœì í™” ë°©ì•ˆ

**ì˜µì…˜ 1: KEYS_ONLY (ê¶Œì¥)**

```python
{
    'IndexName': 'GSI2',
    'KeySchema': [
        {'AttributeName': 'GSI2PK', 'KeyType': 'HASH'}
    ],
    'Projection': {'ProjectionType': 'KEYS_ONLY'}  # âœ… PK, SKë§Œ
}
```

**Repository ì½”ë“œ ë³€ê²½**:

```python
def get_user_by_google_id(self, google_id: str) -> Optional[Dict[str, Any]]:
    """
    Get user by Google ID using GSI2 (KEYS_ONLY)
    """
    # Step 1: Query GSI2 to get PK/SK
    results = self.query(
        key_condition_expression=Key('GSI2PK').eq(f'GID#{google_id}'),
        index_name='GSI2'
    )

    if not results:
        return None

    # Step 2: GetItem to fetch full user data
    pk = results[0]['PK']
    sk = results[0]['SK']
    user_item = self.get_item(pk, sk)

    if not user_item:
        return None

    return self._item_to_user_dict(user_item)
```

**ë¹„ìš© ì˜í–¥**:

| ë©”íŠ¸ë¦­ | Before (ALL) | After (KEYS_ONLY) | ì ˆê° |
|--------|--------------|-------------------|------|
| GSI Storage | 10MB | 1MB | 90% |
| Write WCU | 1 WCU | 0.5 WCU | 50% |
| Query RCU | 0.25 RCU | 0.25 RCU (GSI) + 0.25 RCU (GetItem) | 0% (ë™ì¼) |
| ì›”ê°„ ë¹„ìš© | $0.15 | $0.10 | $0.05/ì›” |

**ê¶Œì¥**: `KEYS_ONLY` ì ìš© (WCU 50% ì ˆê°)

**ë§ˆì´ê·¸ë ˆì´ì…˜**:

```bash
# GSI2ë¥¼ ì‚­ì œí•˜ê³  ì¬ìƒì„± í•„ìš” (Projection ë³€ê²½ì€ in-place ë¶ˆê°€)

# 1. ìƒˆ GSI2_v2 ìƒì„±
aws dynamodb update-table \
    --table-name algoitny_main \
    --attribute-definitions AttributeName=GSI2PK,AttributeType=S \
    --global-secondary-index-updates \
        '[{
            "Create": {
                "IndexName": "GSI2_v2",
                "KeySchema": [{"AttributeName": "GSI2PK", "KeyType": "HASH"}],
                "Projection": {"ProjectionType": "KEYS_ONLY"}
            }
        }]'

# 2. ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ì—…ë°ì´íŠ¸ (GSI2 â†’ GSI2_v2)

# 3. ë°°í¬ í›„ ê¸°ì¡´ GSI2 ì‚­ì œ
aws dynamodb update-table \
    --table-name algoitny_main \
    --global-secondary-index-updates \
        '[{"Delete": {"IndexName": "GSI2"}}]'

# 4. GSI2_v2 â†’ GSI2ë¡œ rename (ìƒˆë¡œìš´ GSI ì¬ìƒì„± í•„ìš”)
```

**ë³µì¡ë„**: ì¤‘ê°„ (GSI ì¬ìƒì„± í•„ìš”)
**ìš°ì„ ìˆœìœ„**: P3 (ë¹„ìš© ì ˆê° ë¯¸ë¯¸, ë¦¬ìŠ¤í¬ ì¡´ì¬)

---

### 6.3 GSI1 ë¶„ì„

**í˜„ì¬ ì‚¬ìš©**:
1. User ì¸ì¦ (`EMAIL#{email}` â†’ User)
2. Job ìƒíƒœ ì¿¼ë¦¬ (`PEJOB#STATUS#{status}` â†’ Jobs)

**í‰ê°€**: âœ… **ìµœì í™”ë¨**

**ì´ìœ **:
- Composite pattern (ì—¬ëŸ¬ ì—”í‹°í‹°ê°€ ë™ì¼ GSI ì‚¬ìš©)
- íš¨ìœ¨ì ì¸ ì¿¼ë¦¬ íŒ¨í„´
- Projection: ALL (í•„ìš”í•œ ë°ì´í„°ê°€ ë§ì•„ ì ì ˆ)

**ë¹„ìš©**:
- Storage: ~50MB
- ì›”ê°„ ë¹„ìš©: ~$0.01 (ë¬´ì‹œ ê°€ëŠ¥)

**ê¶Œì¥**: ë³€ê²½ ë¶ˆí•„ìš”

---

### 6.4 GSI3 ë¶„ì„

**í˜„ì¬ ì‚¬ìš©**:
- Problem ìƒíƒœ ì¸ë±ìŠ¤ (`PROB#COMPLETED`, `PROB#DRAFT`)

**í‰ê°€**: âœ… **ìµœì í™”ë¨**

**ì´ìœ **:
- ëª…í™•í•œ ì¿¼ë¦¬ íŒ¨í„´
- íš¨ìœ¨ì ì¸ Sort Key (timestamp)
- Projection: ALL (Problem ë¦¬ìŠ¤íŠ¸ì— ëª¨ë“  ë°ì´í„° í•„ìš”)

**ì„±ëŠ¥**:
- Query 5 RCU (Scan 5,000 RCU ëŒ€ë¹„ 99.9% ì ˆê°)
- ë ˆì´í„´ì‹œ: 20ms (Scan 1,500ms ëŒ€ë¹„ 98.7% ê°œì„ )

**ê¶Œì¥**: ë³€ê²½ ë¶ˆí•„ìš”

---

### 6.5 ì‹ ê·œ GSI ì¶”ê°€ ê¶Œì¥ì‚¬í•­

#### GSI4: Review Status Index (P0)

**ëª©ì **: `list_problems_needing_review()` Scan ì œê±°

```python
{
    'IndexName': 'GSI4',
    'KeySchema': [
        {'AttributeName': 'GSI4PK', 'KeyType': 'HASH'},  # PROB#REVIEW
        {'AttributeName': 'GSI4SK', 'KeyType': 'RANGE'}  # timestamp
    ],
    'Projection': {
        'ProjectionType': 'INCLUDE',
        'NonKeyAttributes': ['dat', 'crt', 'upd']
    }
}
```

**ë¹„ìš©**:
- Storage: ~5MB (review ëŒ€ê¸° ë¬¸ì œë§Œ)
- ì›”ê°„ ë¹„ìš©: ~$0.001
- **ë¹„ìš© ì ˆê°**: $65/ì›” (Scan ì œê±°)

**ROI**: 65,000x ğŸš€

---

#### GSI5: Active User Index (P1)

**ëª©ì **: `list_active_users()` Scan ì œê±°

```python
{
    'IndexName': 'GSI5',
    'KeySchema': [
        {'AttributeName': 'GSI5PK', 'KeyType': 'HASH'}  # USR#ACTIVE
    ],
    'Projection': {'ProjectionType': 'KEYS_ONLY'}
}
```

**ë¹„ìš©**:
- Storage: ~1MB
- ì›”ê°„ ë¹„ìš©: ~$0.0003
- **ë¹„ìš© ì ˆê°**: $7/ì›”

**ROI**: 23,000x ğŸš€

---

### 6.6 GSI ìµœì í™” ìš”ì•½

| GSI | í˜„ì¬ ìƒíƒœ | ê¶Œì¥ ì¡°ì¹˜ | ì˜ˆìƒ ì ˆê° | ìš°ì„ ìˆœìœ„ |
|-----|-----------|-----------|-----------|----------|
| GSI1 | âœ… ìµœì í™”ë¨ | ì—†ìŒ | - | - |
| GSI2 | âš ï¸ ê³¼ë‹¤ í”„ë¡œì ì…˜ | KEYS_ONLY ì „í™˜ | $0.05/ì›” | P3 |
| GSI3 | âœ… ìµœì í™”ë¨ | ì—†ìŒ | - | - |
| **GSI4** (ì‹ ê·œ) | âŒ ì—†ìŒ | **ìƒì„± í•„ìš”** | **$65/ì›”** | **P0** |
| **GSI5** (ì‹ ê·œ) | âŒ ì—†ìŒ | **ìƒì„± í•„ìš”** | **$7/ì›”** | **P1** |

**ì´ ì˜ˆìƒ ì ˆê°**: $72/ì›” = **$864/ë…„**

---

## 7. ìƒì„¸ êµ¬í˜„ ë¡œë“œë§µ

### Phase 1: Critical Optimizations (P0) - Week 1

#### ëª©í‘œ
- SCAN ì‘ì—… ì œê±° (ê°€ì¥ í° ë¹„ìš© ì ˆê°)
- TTL ì ìš© (ë°ì´í„° ì¦ê°€ ë°©ì§€)

#### ì‘ì—… ëª©ë¡

##### 1.1 GSI4 ìƒì„± (Review Status Index)

**ì˜ˆìƒ ì‹œê°„**: 4ì‹œê°„

**ë‹¨ê³„**:
1. **ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸** (30ë¶„)
   ```python
   # backend/api/dynamodb/table_schema.py
   'AttributeDefinitions': [
       # ... ê¸°ì¡´
       {'AttributeName': 'GSI4PK', 'AttributeType': 'S'},
       {'AttributeName': 'GSI4SK', 'AttributeType': 'N'},
   ],

   'GlobalSecondaryIndexes': [
       # ... ê¸°ì¡´
       {
           'IndexName': 'GSI4',
           'KeySchema': [
               {'AttributeName': 'GSI4PK', 'KeyType': 'HASH'},
               {'AttributeName': 'GSI4SK', 'KeyType': 'RANGE'}
           ],
           'Projection': {
               'ProjectionType': 'INCLUDE',
               'NonKeyAttributes': ['dat', 'crt', 'upd']
           }
       }
   ]
   ```

2. **AWSì— GSI4 ì¶”ê°€** (15ë¶„ + 10ë¶„ ëŒ€ê¸°)
   ```bash
   aws dynamodb update-table \
       --table-name algoitny_main \
       --attribute-definitions \
           AttributeName=GSI4PK,AttributeType=S \
           AttributeName=GSI4SK,AttributeType=N \
       --global-secondary-index-updates file://gsi4_create.json

   # gsi4_create.json
   [{
       "Create": {
           "IndexName": "GSI4",
           "KeySchema": [
               {"AttributeName": "GSI4PK", "KeyType": "HASH"},
               {"AttributeName": "GSI4SK", "KeyType": "RANGE"}
           ],
           "Projection": {
               "ProjectionType": "INCLUDE",
               "NonKeyAttributes": ["dat", "crt", "upd"]
           }
       }
   }]
   ```

3. **ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜** (1ì‹œê°„)
   ```bash
   # scripts/migrate_gsi4.py ì‘ì„± ë° ì‹¤í–‰
   python scripts/migrate_gsi4.py

   # ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: 100 problems Ã— 0.1s = 10ì´ˆ
   ```

4. **Repository ì½”ë“œ ì—…ë°ì´íŠ¸** (1ì‹œê°„)
   - `problem_repository.py` ìˆ˜ì •
   - `list_problems_needing_review()` Queryë¡œ ë³€ê²½
   - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

5. **í†µí•© í…ŒìŠ¤íŠ¸** (30ë¶„)
   ```bash
   # LocalStackì—ì„œ í…ŒìŠ¤íŠ¸
   pytest tests/test_problem_repository.py::test_list_problems_needing_review

   # API í…ŒìŠ¤íŠ¸
   curl -H "Authorization: Bearer <token>" \
        http://localhost:8000/api/admin/problems/review/
   ```

6. **í”„ë¡œë•ì…˜ ë°°í¬** (30ë¶„)
   ```bash
   # ë°°í¬
   git add .
   git commit -m "feat: Add GSI4 for review queue optimization"
   git push origin main

   # ì„œë²„ ì¬ì‹œì‘
   docker-compose restart backend

   # ëª¨ë‹ˆí„°ë§
   docker logs -f algoitny-backend
   ```

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] GSI4ê°€ AWSì— ìƒì„±ë¨ (`ACTIVE` ìƒíƒœ)
- [ ] ëª¨ë“  review ëŒ€ê¸° ë¬¸ì œì— GSI4PK/GSI4SK ì¶”ê°€ë¨
- [ ] `list_problems_needing_review()` ì‘ë‹µ ì‹œê°„ < 50ms
- [ ] Scan ì‘ì—…ì´ CloudWatchì—ì„œ ì‚¬ë¼ì§
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ 100% í†µê³¼

**ì˜ˆìƒ ë¹„ìš© ì ˆê°**: $65/ì›”

---

##### 1.2 SearchHistory TTL ì ìš©

**ì˜ˆìƒ ì‹œê°„**: 2ì‹œê°„

**ë‹¨ê³„**:
1. **TTL í™œì„±í™”** (5ë¶„)
   ```bash
   aws dynamodb update-time-to-live \
       --table-name algoitny_main \
       --time-to-live-specification \
           "Enabled=true, AttributeName=ttl"
   ```

2. **Repository ì½”ë“œ ìˆ˜ì •** (30ë¶„)
   ```python
   # search_history_repository.py
   def create_history(self, ...):
       timestamp = int(time.time())

       item = {
           # ... ê¸°ì¡´ í•„ë“œ
           'ttl': timestamp + (90 * 86400),  # 90ì¼
       }
   ```

3. **ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸** (30ë¶„)
   ```python
   # scripts/migrate_history_ttl.py
   # ê¸°ì¡´ SearchHistory ì•„ì´í…œì— TTL ì¶”ê°€
   ```

4. **í…ŒìŠ¤íŠ¸** (30ë¶„)
   ```bash
   # TTL ë™ì‘ í™•ì¸ (LocalStack)
   python scripts/test_ttl.py

   # API í…ŒìŠ¤íŠ¸
   curl -X POST http://localhost:8000/api/execute/ \
        -H "Content-Type: application/json" \
        -d '{"code": "print(1)", ...}'
   ```

5. **ë°°í¬** (30ë¶„)

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] TTL ì†ì„±ì´ í™œì„±í™”ë¨
- [ ] ëª¨ë“  ìƒˆ SearchHistoryì— `ttl` í•„ë“œ í¬í•¨
- [ ] ê¸°ì¡´ ì•„ì´í…œì— TTL ì¶”ê°€ë¨ (ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ)
- [ ] 90ì¼ í›„ ìë™ ì‚­ì œ í™•ì¸ (CloudWatch Logs)

**ì˜ˆìƒ ë¹„ìš© ì ˆê°**: $3/ì›” (ì¦‰ì‹œ), $9/ì›” (3ë…„ í›„)

---

##### 1.3 JobProgressHistory TTL ì ìš©

**ì˜ˆìƒ ì‹œê°„**: 1ì‹œê°„

**ë‹¨ê³„**:
1. **Repository ì½”ë“œ ìˆ˜ì •** (20ë¶„)
   ```python
   # job_progress_repository.py
   def add_progress(self, ...):
       timestamp = int(time.time())

       item = {
           # ... ê¸°ì¡´ í•„ë“œ
           'ttl': timestamp + (7 * 86400),  # 7ì¼
       }
   ```

2. **ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸** (20ë¶„)

3. **í…ŒìŠ¤íŠ¸ ë° ë°°í¬** (20ë¶„)

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ëª¨ë“  ìƒˆ JobProgressì— `ttl=7ì¼` ì ìš©
- [ ] ê¸°ì¡´ ì•„ì´í…œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ

**ì˜ˆìƒ ë¹„ìš© ì ˆê°**: $0.03/ì›” (ë¯¸ë¯¸í•˜ì§€ë§Œ ë°ì´í„° ì •ë¦¬)

---

### Phase 2: High Priority Optimizations (P1) - Week 2

#### ëª©í‘œ
- User ê´€ë ¨ Scan ìµœì í™”
- í˜ì´ì§€ë„¤ì´ì…˜ ë° ìºì‹± ì ìš©

#### ì‘ì—… ëª©ë¡

##### 2.1 GSI5 ìƒì„± (Active User Index)

**ì˜ˆìƒ ì‹œê°„**: 3ì‹œê°„

**ë‹¨ê³„**:
1. **ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸** (30ë¶„)
2. **AWSì— GSI5 ì¶”ê°€** (15ë¶„ + 10ë¶„ ëŒ€ê¸°)
3. **ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜** (1ì‹œê°„)
4. **Repository ì½”ë“œ ì—…ë°ì´íŠ¸** (1ì‹œê°„)
5. **í…ŒìŠ¤íŠ¸ ë° ë°°í¬** (30ë¶„)

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] GSI5ê°€ ìƒì„±ë¨
- [ ] `list_active_users()` Queryë¡œ ë³€ê²½
- [ ] ì‘ë‹µ ì‹œê°„ < 100ms

**ì˜ˆìƒ ë¹„ìš© ì ˆê°**: $7/ì›”

---

##### 2.2 User List í˜ì´ì§€ë„¤ì´ì…˜ ë° ìºì‹±

**ì˜ˆìƒ ì‹œê°„**: 4ì‹œê°„

**ë‹¨ê³„**:
1. **ìºì‹± ë¯¸ë“¤ì›¨ì–´ ì‘ì„±** (1ì‹œê°„)
   ```python
   # api/middleware/cache_middleware.py
   ```

2. **Repository ë©”ì†Œë“œ ìˆ˜ì •** (2ì‹œê°„)
   - `list_users_paginated()` ì¶”ê°€
   - ìºì‹± ë°ì½”ë ˆì´í„° ì ìš©

3. **View ì—…ë°ì´íŠ¸** (1ì‹œê°„)
   - í˜ì´ì§€ë„¤ì´ì…˜ ì§€ì›
   - ìºì‹œ ì‘ë‹µ ì¶”ê°€

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] User list APIê°€ í˜ì´ì§€ë„¤ì´ì…˜ ì§€ì›
- [ ] 5ë¶„ ìºì‹œ ì ìš©
- [ ] Cache hit rate > 80%

**ì˜ˆìƒ ë¹„ìš© ì ˆê°**: $35/ì›” (ì¦‰ì‹œ), $42/ì›” (ìºì‹± íš¨ê³¼)

---

##### 2.3 get_users_by_plan() ìºì‹±

**ì˜ˆìƒ ì‹œê°„**: 1ì‹œê°„

**ë‹¨ê³„**:
1. **ìºì‹± ì¶”ê°€** (30ë¶„)
2. **í…ŒìŠ¤íŠ¸** (30ë¶„)

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] 10ë¶„ ìºì‹œ ì ìš©
- [ ] Cache invalidation ë¡œì§ ì¶”ê°€ (Plan ë³€ê²½ ì‹œ)

**ì˜ˆìƒ ë¹„ìš© ì ˆê°**: $3/ì›”

---

### Phase 3: Medium Priority (P2) - Week 3

#### ëª©í‘œ
- SearchHistory íŒŒí‹°ì…”ë‹ (Hot Partition ì˜ˆë°©)
- Job TTL ì ìš©

#### ì‘ì—… ëª©ë¡

##### 3.1 SearchHistory GSI2 íŒŒí‹°ì…”ë‹

**ì˜ˆìƒ ì‹œê°„**: 4ì‹œê°„

**ë‹¨ê³„**:
1. **Repository ì½”ë“œ ìˆ˜ì •** (2ì‹œê°„)
   - ì‹œê°„ ê¸°ë°˜ íŒŒí‹°ì…”ë‹ ë¡œì§ ì¶”ê°€
   - `list_public_history_last_24h()` êµ¬í˜„

2. **ê¸°ì¡´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜** (1ì‹œê°„)
   - ê¸°ì¡´ `GSI2PK = 'PUBLIC#HIST'` â†’ `PUBLIC#HIST#{partition}`

3. **í…ŒìŠ¤íŠ¸ ë° ë°°í¬** (1ì‹œê°„)

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ëª¨ë“  ìƒˆ public historyê°€ ì‹œê°„ íŒŒí‹°ì…˜ ì‚¬ìš©
- [ ] ê¸°ì¡´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ
- [ ] íŒŒí‹°ì…˜ë‹¹ ì•„ì´í…œ ìˆ˜ < 1,000ê°œ

**ì˜ˆìƒ íš¨ê³¼**: Hot Partition ìœ„í—˜ ì œê±° (í–¥í›„ 10K+ users ëŒ€ë¹„)

---

##### 3.2 Job TTL ì ìš©

**ì˜ˆìƒ ì‹œê°„**: 2ì‹œê°„

**ë‹¨ê³„**:
1. **ì™„ë£Œëœ Jobì— TTL ì¶”ê°€** (1ì‹œê°„)
2. **ë§ˆì´ê·¸ë ˆì´ì…˜ ë° í…ŒìŠ¤íŠ¸** (1ì‹œê°„)

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ì™„ë£Œ/ì‹¤íŒ¨ Jobì— 30ì¼ TTL ì ìš©

**ì˜ˆìƒ ë¹„ìš© ì ˆê°**: $0.01/ì›” (ë¯¸ë¯¸)

---

### Phase 4: Low Priority (P3) - Future

#### ëª©í‘œ
- GSI2 Projection ìµœì í™”
- SubscriptionPlan ìºì‹±

#### ì‘ì—… ëª©ë¡

##### 4.1 GSI2 KEYS_ONLY ì „í™˜

**ì˜ˆìƒ ì‹œê°„**: 4ì‹œê°„

**ë³µì¡ë„**: ë†’ìŒ (GSI ì¬ìƒì„± í•„ìš”)

**ë‹¨ê³„**:
1. **GSI2_v2 ìƒì„±** (KEYS_ONLY) - 15ë¶„
2. **ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ì—…ë°ì´íŠ¸** - 2ì‹œê°„
3. **ë°°í¬ ë° ê²€ì¦** - 1ì‹œê°„
4. **ê¸°ì¡´ GSI2 ì‚­ì œ** - 30ë¶„
5. **GSI2_v2 â†’ GSI2 rename** - 30ë¶„

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] GSI2ê°€ KEYS_ONLY projection ì‚¬ìš©
- [ ] `get_user_by_google_id()` ì •ìƒ ë™ì‘

**ì˜ˆìƒ ë¹„ìš© ì ˆê°**: $0.05/ì›” (ë¯¸ë¯¸)

**ê¶Œì¥**: ë³´ë¥˜ (ë¦¬ìŠ¤í¬ ëŒ€ë¹„ íš¨ê³¼ ë‚®ìŒ)

---

##### 4.2 SubscriptionPlan ìºì‹±

**ì˜ˆìƒ ì‹œê°„**: 30ë¶„

**ë‹¨ê³„**:
1. **ìºì‹± ì¶”ê°€** (15ë¶„)
2. **í…ŒìŠ¤íŠ¸** (15ë¶„)

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] Plan listê°€ 1ì‹œê°„ ìºì‹±ë¨

**ì˜ˆìƒ íš¨ê³¼**: ë¬´ì‹œ ê°€ëŠ¥ (ì´ë¯¸ ì €ë¹„ìš©)

---

### ì „ì²´ êµ¬í˜„ íƒ€ì„ë¼ì¸

```
Week 1 (Phase 1 - Critical):
  Day 1-2: GSI4 ìƒì„± ë° ë§ˆì´ê·¸ë ˆì´ì…˜
  Day 3: SearchHistory TTL
  Day 4: JobProgressHistory TTL
  Day 5: í†µí•© í…ŒìŠ¤íŠ¸ ë° ë°°í¬

Week 2 (Phase 2 - High):
  Day 1-2: GSI5 ìƒì„± ë° ë§ˆì´ê·¸ë ˆì´ì…˜
  Day 3-4: User list í˜ì´ì§€ë„¤ì´ì…˜ ë° ìºì‹±
  Day 5: í†µí•© í…ŒìŠ¤íŠ¸ ë° ë°°í¬

Week 3 (Phase 3 - Medium):
  Day 1-2: SearchHistory íŒŒí‹°ì…”ë‹
  Day 3: Job TTL
  Day 4-5: í†µí•© í…ŒìŠ¤íŠ¸ ë° ë°°í¬

Week 4+ (Phase 4 - Low):
  - ì„ íƒì  ìµœì í™” (í•„ìš” ì‹œ)
```

---

### êµ¬í˜„ ìš°ì„ ìˆœìœ„ ìš”ì•½

| Phase | ì‘ì—… | ì˜ˆìƒ ì‹œê°„ | ë¹„ìš© ì ˆê° | ROI | ìƒíƒœ |
|-------|------|-----------|-----------|-----|------|
| **P0** | GSI4 ìƒì„± | 4h | $65/ì›” | 16.25x | ğŸ”´ Critical |
| **P0** | SearchHistory TTL | 2h | $3/ì›” (ì¦‰ì‹œ), $9/ì›” (ì¥ê¸°) | 4.5x | ğŸ”´ Critical |
| **P0** | JobProgress TTL | 1h | $0.03/ì›” | 0.03x | ğŸŸ¡ ë‚®ìŒ |
| **P1** | GSI5 ìƒì„± | 3h | $7/ì›” | 2.33x | ğŸŸ  High |
| **P1** | User í˜ì´ì§€ë„¤ì´ì…˜ | 4h | $35/ì›” | 8.75x | ğŸŸ  High |
| **P1** | User by Plan ìºì‹± | 1h | $3/ì›” | 3x | ğŸŸ¡ Medium |
| **P2** | History íŒŒí‹°ì…”ë‹ | 4h | $0 (ì˜ˆë°©) | 0x | ğŸŸ¢ ì˜ˆë°© |
| **P2** | Job TTL | 2h | $0.01/ì›” | 0.005x | ğŸŸ¢ ë‚®ìŒ |
| **P3** | GSI2 ìµœì í™” | 4h | $0.05/ì›” | 0.0125x | âšª ì„ íƒ |
| **P3** | Plan ìºì‹± | 0.5h | $0/ì›” | 0x | âšª ì„ íƒ |

**ì´ ì˜ˆìƒ ì‹œê°„**: 25.5ì‹œê°„ (ì•½ 3ì£¼)
**ì´ ì˜ˆìƒ ë¹„ìš© ì ˆê°**: **$193/ì›”** = **$2,316/ë…„**

---

## 8. ë¦¬ìŠ¤í¬ ë° ì™„í™” ì „ëµ

### 8.1 GSI ìƒì„± ë¦¬ìŠ¤í¬

**ë¦¬ìŠ¤í¬**:
- GSI ìƒì„± ì¤‘ í…Œì´ë¸” ì„±ëŠ¥ ì €í•˜
- ë°±í•„ ì‹œê°„ ì§€ì—° (ëŒ€ëŸ‰ ë°ì´í„° ì‹œ)

**ì™„í™” ì „ëµ**:
1. **Off-Peak ì‹œê°„ ë°°í¬**: ìƒˆë²½ 2-4ì‹œ (UTC)
2. **ë‹¨ê³„ì  ë¡¤ì•„ì›ƒ**: LocalStack â†’ Staging â†’ Production
3. **ëª¨ë‹ˆí„°ë§ ê°•í™”**: CloudWatch ì•ŒëŒ ì„¤ì •
4. **ë¡¤ë°± ê³„íš**: ê¸°ì¡´ Scan ì½”ë“œ ì£¼ì„ ì²˜ë¦¬ (1ì‹œê°„ ë‚´ ë³µêµ¬)

**ë¡¤ë°± ì ˆì°¨**:
```python
# problem_repository.py
def list_problems_needing_review(self, limit=100):
    # New: Query GSI4
    try:
        response = self.table.query(
            IndexName='GSI4',
            KeyConditionExpression=Key('GSI4PK').eq('PROB#REVIEW'),
            Limit=limit
        )
        # ... process
    except Exception as e:
        logger.error(f"GSI4 query failed: {e}, falling back to Scan")
        # Fallback: Old Scan method
        items = self.scan(
            filter_expression=Attr('tp').eq('prob') &
                            Attr('dat.nrv').eq(True),
            limit=limit
        )
        # ... process
```

---

### 8.2 ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬ìŠ¤í¬

**ë¦¬ìŠ¤í¬**:
- ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ë°ì´í„° ë¶ˆì¼ì¹˜
- ëŒ€ëŸ‰ ì“°ê¸°ë¡œ ì¸í•œ WCU throttling

**ì™„í™” ì „ëµ**:
1. **Batch Write ì‚¬ìš©**: 25ê°œì”© ë°°ì¹˜ ì²˜ë¦¬
2. **Rate Limiting**: ì´ˆë‹¹ ìµœëŒ€ 100 WCU ì‚¬ìš©
3. **Idempotency**: ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì¬ì‹¤í–‰ ê°€ëŠ¥
4. **Progress Tracking**: ì§„í–‰ ìƒí™© ë¡œê¹…

**ì˜ˆì‹œ ìŠ¤í¬ë¦½íŠ¸**:
```python
import time
from boto3.dynamodb.conditions import Attr

def migrate_with_rate_limit(table, items, wcu_limit=100):
    """
    Migrate items with WCU rate limiting
    """
    batch_size = 25
    delay_per_batch = 0.25  # 250ms delay = 100 WCU/sec limit

    migrated = 0
    failed = []

    for i in range(0, len(items), batch_size):
        batch = items[i:i+batch_size]

        try:
            with table.batch_writer() as writer:
                for item in batch:
                    writer.put_item(Item=item)

            migrated += len(batch)
            logger.info(f"Migrated {migrated}/{len(items)} items")

            # Rate limiting
            time.sleep(delay_per_batch)

        except Exception as e:
            logger.error(f"Batch failed: {e}")
            failed.extend(batch)

    # Retry failed items
    for item in failed:
        try:
            table.put_item(Item=item)
            migrated += 1
        except Exception as e:
            logger.error(f"Item failed: {item['PK']}")

    return migrated, len(failed)
```

---

### 8.3 TTL ë¦¬ìŠ¤í¬

**ë¦¬ìŠ¤í¬**:
- ì¤‘ìš”í•œ ë°ì´í„° ì‹¤ìˆ˜ë¡œ ì‚­ì œ
- TTL ì‚­ì œ ì§€ì—° (ìµœëŒ€ 48ì‹œê°„)

**ì™„í™” ì „ëµ**:
1. **ë³´ì¡´ ì •ì±…**: ì¤‘ìš” ë°ì´í„°ëŠ” TTL ë¯¸ì ìš©
2. **ë°±ì—… ì „ëµ**: DynamoDB On-Demand Backup í™œì„±í™”
3. **ì†Œí”„íŠ¸ ì‚­ì œ**: TTL ì „ì— `is_deleted=true` ë§ˆí‚¹ (ë³µêµ¬ ê°€ëŠ¥)
4. **ì•Œë¦¼**: TTL ì‚­ì œ ì‹œ CloudWatch ì•ŒëŒ

**TTL ì•ˆì „ ì„¤ì •**:
```python
# ì¤‘ìš” ë°ì´í„°ëŠ” TTL ì œì™¸
def create_history(self, ..., is_important=False):
    item = {
        # ... ê¸°ë³¸ í•„ë“œ
    }

    # ì¤‘ìš” ë°ì´í„°ëŠ” TTL ë¯¸ì ìš©
    if not is_important:
        item['ttl'] = timestamp + (90 * 86400)

    return item
```

---

### 8.4 ìºì‹± ë¦¬ìŠ¤í¬

**ë¦¬ìŠ¤í¬**:
- Stale ë°ì´í„° ì œê³µ
- Cache invalidation ì‹¤íŒ¨

**ì™„í™” ì „ëµ**:
1. **ì§§ì€ TTL**: 5-15ë¶„ (ì‹¤ì‹œê°„ì„± ìœ ì§€)
2. **Cache Invalidation**: ë°ì´í„° ë³€ê²½ ì‹œ ìˆ˜ë™ ë¬´íš¨í™”
3. **Cache-Aside íŒ¨í„´**: Cache miss ì‹œ DB ì¡°íšŒ
4. **Monitoring**: Cache hit rate ëª¨ë‹ˆí„°ë§ (ëª©í‘œ >80%)

**Cache Invalidation ì˜ˆì‹œ**:
```python
from django.core.cache import cache

def update_user(self, user_id, updates):
    # Update DynamoDB
    updated_user = self.table.update_item(...)

    # Invalidate cache
    cache_keys = [
        f'user:{user_id}',
        f'user_list:*',  # All user lists
        f'users_by_plan:{updates.get("subscription_plan_id")}',
    ]

    for key in cache_keys:
        cache.delete(key)

    return updated_user
```

---

## 9. ì„±ê³µ ì§€í‘œ (KPI)

### 9.1 ë¹„ìš© ì§€í‘œ

| ì§€í‘œ | í˜„ì¬ | ëª©í‘œ (3ê°œì›” í›„) | ì¸¡ì • ë°©ë²• |
|------|------|-----------------|-----------|
| ì›”ê°„ RCU | 1,200,000 | 15,000 (-98.75%) | CloudWatch |
| ì›”ê°„ WCU | 50,000 | 50,000 (ë™ì¼) | CloudWatch |
| ì›”ê°„ Storage | 200MB | 50MB (-75%) | AWS Console |
| ì›”ê°„ DynamoDB ë¹„ìš© | $210 | $17 (-91.9%) | AWS Billing |

---

### 9.2 ì„±ëŠ¥ ì§€í‘œ

| API ì—”ë“œí¬ì¸íŠ¸ | í˜„ì¬ P99 | ëª©í‘œ P99 | ì¸¡ì • ë°©ë²• |
|---------------|----------|----------|-----------|
| GET /api/problems/ | 500ms | 50ms | APM Tool |
| GET /api/admin/problems/review/ | 2,000ms | 50ms | APM Tool |
| GET /api/admin/users/ | 1,200ms | 100ms | APM Tool |
| GET /api/admin/stats/ | 8,000ms | 100ms | APM Tool |

---

### 9.3 ìš´ì˜ ì§€í‘œ

| ì§€í‘œ | í˜„ì¬ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|------|-----------|
| Scan ì‘ì—…/ì¼ | 500 | < 50 | CloudWatch Logs |
| Query ì‘ì—…/ì¼ | 1,000 | 10,000+ | CloudWatch Logs |
| Cache Hit Rate | 0% | > 80% | Application Logs |
| TTL ì‚­ì œ/ì¼ | 0 | 500+ | CloudWatch Metrics |

---

### 9.4 ë°ì´í„° ì¦ê°€ ì œì–´

| ì—”í‹°í‹° | í˜„ì¬ ì¦ê°€ìœ¨ | ëª©í‘œ ì¦ê°€ìœ¨ | ì œì–´ ë°©ë²• |
|--------|-------------|-------------|-----------|
| SearchHistory | ë¬´ì œí•œ | 90ì¼ ìœ ì§€ | TTL |
| JobProgress | ë¬´ì œí•œ | 7ì¼ ìœ ì§€ | TTL |
| UsageLog | âœ… 90ì¼ | 90ì¼ ìœ ì§€ | ê¸°ì¡´ TTL |

---

## 10. ì°¸ê³  ìë£Œ

### 10.1 DynamoDB ê³µì‹ ë¬¸ì„œ

- [DynamoDB Best Practices](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/best-practices.html)
- [Global Secondary Indexes](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html)
- [Time To Live (TTL)](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html)
- [Query vs Scan](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-query-scan.html)

---

### 10.2 ë‚´ë¶€ ë¬¸ì„œ

- `/Users/gwonsoolee/algoitny/backend/DYNAMODB_INDEX_ANALYSIS.md`
- `/Users/gwonsoolee/algoitny/backend/docs/DYNAMODB_OPTIMIZATIONS_SUMMARY.md`
- `/Users/gwonsoolee/algoitny/backend/docs/DYNAMODB_SIZE_LIMIT_ANALYSIS.md`

---

### 10.3 ë¹„ìš© ê³„ì‚°ê¸°

- [AWS Pricing Calculator](https://calculator.aws/)
- [DynamoDB Pricing](https://aws.amazon.com/dynamodb/pricing/)

---

## 11. ìµœì¢… ê¶Œì¥ì‚¬í•­

### 11.1 ì¦‰ì‹œ ì‹¤í–‰ (P0)

1. âœ… **GSI4 ìƒì„±** (Review Queue Index)
   - ì˜ˆìƒ ì ˆê°: $65/ì›”
   - êµ¬í˜„ ì‹œê°„: 4ì‹œê°„
   - ROI: 16.25x

2. âœ… **SearchHistory TTL ì ìš©** (90ì¼)
   - ì˜ˆìƒ ì ˆê°: $9/ì›” (ì¥ê¸°)
   - êµ¬í˜„ ì‹œê°„: 2ì‹œê°„
   - ROI: 4.5x

**ì´ ì˜ˆìƒ ì ˆê°**: $74/ì›” = $888/ë…„

---

### 11.2 2ì£¼ ë‚´ ì‹¤í–‰ (P1)

1. âœ… **GSI5 ìƒì„±** (Active User Index)
   - ì˜ˆìƒ ì ˆê°: $7/ì›”
   - êµ¬í˜„ ì‹œê°„: 3ì‹œê°„

2. âœ… **User List í˜ì´ì§€ë„¤ì´ì…˜ ë° ìºì‹±**
   - ì˜ˆìƒ ì ˆê°: $42/ì›”
   - êµ¬í˜„ ì‹œê°„: 4ì‹œê°„

**ì¶”ê°€ ì ˆê°**: $49/ì›” = $588/ë…„

---

### 11.3 1ê°œì›” ë‚´ ì‹¤í–‰ (P2)

1. âœ… **SearchHistory íŒŒí‹°ì…”ë‹** (Hot Partition ì˜ˆë°©)
   - ì˜ˆìƒ íš¨ê³¼: í–¥í›„ 10K+ users ëŒ€ë¹„
   - êµ¬í˜„ ì‹œê°„: 4ì‹œê°„

2. âœ… **JobProgress TTL ì ìš©** (7ì¼)
   - ì˜ˆìƒ ì ˆê°: $0.03/ì›”
   - êµ¬í˜„ ì‹œê°„: 1ì‹œê°„

**ì¶”ê°€ ì ˆê°**: $0.03/ì›” = $0.36/ë…„

---

### 11.4 ì„ íƒì  ì‹¤í–‰ (P3)

1. âš ï¸ **GSI2 ìµœì í™”** (KEYS_ONLY)
   - ì˜ˆìƒ ì ˆê°: $0.05/ì›”
   - êµ¬í˜„ ì‹œê°„: 4ì‹œê°„
   - **ê¶Œì¥**: ë³´ë¥˜ (ë¦¬ìŠ¤í¬ ëŒ€ë¹„ íš¨ê³¼ ë‚®ìŒ)

2. âš ï¸ **SubscriptionPlan ìºì‹±**
   - ì˜ˆìƒ íš¨ê³¼: ë¬´ì‹œ ê°€ëŠ¥
   - **ê¶Œì¥**: ë³´ë¥˜

---

### 11.5 ì „ì²´ ì˜ˆìƒ íš¨ê³¼

| ê¸°ê°„ | ë¹„ìš© ì ˆê° | ëˆ„ì  ì ˆê° |
|------|-----------|-----------|
| 1ê°œì›” í›„ | $74/ì›” | $74 |
| 3ê°œì›” í›„ | $123/ì›” | $296 |
| 6ê°œì›” í›„ | $193/ì›” | $888 |
| 1ë…„ í›„ | $193/ì›” | $2,316 |
| 3ë…„ í›„ | $193/ì›” | $6,948 |

**3ë…„ ì´ ì ˆê°**: **$6,948** (~900ë§Œì›)

---

## 12. ê²°ë¡ 

ì´ ë³´ê³ ì„œëŠ” algoitny í”„ë¡œì íŠ¸ì˜ DynamoDB ì ‘ê·¼ íŒ¨í„´ì„ ìƒì„¸íˆ ë¶„ì„í•˜ê³ , **91.9%ì˜ ë¹„ìš© ì ˆê°** ê¸°íšŒë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.

### í•µì‹¬ ë°œê²¬ì‚¬í•­

1. **5ê°œì˜ SCAN ì‘ì—…** ë°œê²¬ (ì›” $150 ë¹„ìš©)
2. **3ê°œì˜ TTL ë¯¸ì ìš©** ì—”í‹°í‹° (ì¥ê¸° ë°ì´í„° ì¦ê°€)
3. **2ê°œì˜ GSI ì¶”ê°€** í•„ìš” (GSI4, GSI5)
4. **Hot Partition ìœ„í—˜** ë‚®ìŒ (í˜„ì¬ ì•ˆì „)

### ìš°ì„ ìˆœìœ„

**P0 (ì¦‰ì‹œ)**:
- GSI4 ìƒì„± â†’ **$65/ì›” ì ˆê°**
- SearchHistory TTL â†’ **$9/ì›” ì ˆê° (ì¥ê¸°)**

**P1 (2ì£¼)**:
- GSI5 ìƒì„± â†’ **$7/ì›” ì ˆê°**
- User í˜ì´ì§€ë„¤ì´ì…˜ â†’ **$42/ì›” ì ˆê°**

**P2 (1ê°œì›”)**:
- History íŒŒí‹°ì…”ë‹ (ì˜ˆë°©)
- JobProgress TTL

**ì´ ì˜ˆìƒ ì ˆê°**: **$193/ì›”** = **$2,316/ë…„**

---

## ë¶€ë¡ A: ìŠ¤í¬ë¦½íŠ¸ ì˜ˆì œ

### A.1 GSI4 ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

```python
"""
scripts/migrate_gsi4.py
Add GSI4 attributes to existing problems
"""
import boto3
import time
import os
from boto3.dynamodb.conditions import Attr

# Configuration
ENDPOINT_URL = os.getenv('DYNAMODB_ENDPOINT_URL', 'http://localhost:4566')
TABLE_NAME = 'algoitny_main'

# Initialize DynamoDB
dynamodb = boto3.resource('dynamodb', endpoint_url=ENDPOINT_URL)
table = dynamodb.Table(TABLE_NAME)

def migrate_gsi4():
    """Add GSI4PK/GSI4SK to problems needing review"""
    print("=" * 60)
    print("GSI4 Migration - Review Queue Index")
    print("=" * 60)

    # Scan problems that need review
    print("\n1. Scanning problems needing review...")
    response = table.scan(
        FilterExpression=Attr('tp').eq('prob') &
                        Attr('dat.nrv').eq(True) &
                        Attr('SK').eq('META')
    )

    items = response.get('Items', [])
    print(f"   Found {len(items)} problems needing review")

    if len(items) == 0:
        print("   No problems to migrate")
        return

    # Migrate each item
    print("\n2. Adding GSI4 attributes...")
    migrated = 0
    failed = []

    for item in items:
        pk = item['PK']
        sk = item['SK']
        timestamp = item.get('crt', int(time.time()))

        try:
            # Add GSI4PK and GSI4SK
            table.update_item(
                Key={'PK': pk, 'SK': sk},
                UpdateExpression='SET GSI4PK = :gsi4pk, GSI4SK = :gsi4sk',
                ExpressionAttributeValues={
                    ':gsi4pk': 'PROB#REVIEW',
                    ':gsi4sk': timestamp
                }
            )
            migrated += 1
            print(f"   âœ“ Migrated: {pk}")

        except Exception as e:
            print(f"   âœ— Failed: {pk} - {e}")
            failed.append(pk)

    # Summary
    print("\n" + "=" * 60)
    print("Migration Summary")
    print("=" * 60)
    print(f"Total items: {len(items)}")
    print(f"Migrated: {migrated}")
    print(f"Failed: {len(failed)}")

    if failed:
        print("\nFailed items:")
        for pk in failed:
            print(f"  - {pk}")

    print("\nâœ“ Migration complete!")

if __name__ == '__main__':
    migrate_gsi4()
```

---

### A.2 SearchHistory TTL ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

```python
"""
scripts/migrate_history_ttl.py
Add TTL to existing SearchHistory items
"""
import boto3
import time
import os
from boto3.dynamodb.conditions import Attr

ENDPOINT_URL = os.getenv('DYNAMODB_ENDPOINT_URL', 'http://localhost:4566')
TABLE_NAME = 'algoitny_main'
TTL_DAYS = 90

dynamodb = boto3.resource('dynamodb', endpoint_url=ENDPOINT_URL)
table = dynamodb.Table(TABLE_NAME)

def migrate_history_ttl():
    """Add TTL to existing SearchHistory items"""
    print("=" * 60)
    print("SearchHistory TTL Migration (90 days)")
    print("=" * 60)

    # Scan all history items
    print("\n1. Scanning SearchHistory items...")
    response = table.scan(
        FilterExpression=Attr('tp').eq('hist')
    )

    items = response.get('Items', [])
    print(f"   Found {len(items)} history items")

    if len(items) == 0:
        print("   No items to migrate")
        return

    # Migrate each item
    print("\n2. Adding TTL attributes...")
    migrated = 0
    deleted = 0
    failed = []

    for item in items:
        pk = item['PK']
        sk = item['SK']
        created_at = item.get('crt', int(time.time()))

        # Calculate TTL (90 days from creation)
        ttl_timestamp = created_at + (TTL_DAYS * 86400)

        try:
            # Check if already expired
            if ttl_timestamp < time.time():
                # Delete expired item
                table.delete_item(Key={'PK': pk, 'SK': sk})
                deleted += 1
                print(f"   âœ“ Deleted expired: {pk}")
            else:
                # Add TTL
                table.update_item(
                    Key={'PK': pk, 'SK': sk},
                    UpdateExpression='SET #ttl = :ttl',
                    ExpressionAttributeNames={'#ttl': 'ttl'},
                    ExpressionAttributeValues={':ttl': ttl_timestamp}
                )
                migrated += 1
                print(f"   âœ“ Migrated: {pk}")

        except Exception as e:
            print(f"   âœ— Failed: {pk} - {e}")
            failed.append(pk)

    # Summary
    print("\n" + "=" * 60)
    print("Migration Summary")
    print("=" * 60)
    print(f"Total items: {len(items)}")
    print(f"Migrated (TTL added): {migrated}")
    print(f"Deleted (expired): {deleted}")
    print(f"Failed: {len(failed)}")

    if failed:
        print("\nFailed items:")
        for pk in failed:
            print(f"  - {pk}")

    print("\nâœ“ Migration complete!")

if __name__ == '__main__':
    migrate_history_ttl()
```

---

## ë¶€ë¡ B: ëª¨ë‹ˆí„°ë§ ì¿¼ë¦¬

### B.1 CloudWatch Insights ì¿¼ë¦¬

**Scan ì‘ì—… ëª¨ë‹ˆí„°ë§**:
```
fields @timestamp, @message
| filter @message like /Scan/
| stats count() as scan_count by bin(5m)
```

**Query ì‘ì—… ëª¨ë‹ˆí„°ë§**:
```
fields @timestamp, @message
| filter @message like /Query/
| stats count() as query_count by bin(5m)
```

**GSI4 ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**:
```
fields @timestamp, requestParameters.indexName, responseElements.consumedCapacity
| filter requestParameters.tableName = "algoitny_main"
| filter requestParameters.indexName = "GSI4"
| stats avg(responseElements.consumedCapacity.capacityUnits) as avg_rcu
```

---

### B.2 ì•ŒëŒ ì„¤ì •

**Scan ì‘ì—… ì•ŒëŒ**:
```bash
aws cloudwatch put-metric-alarm \
  --alarm-name "DynamoDB-High-Scan-Count" \
  --alarm-description "Alert when Scan operations exceed threshold" \
  --metric-name UserErrors \
  --namespace AWS/DynamoDB \
  --statistic Sum \
  --period 300 \
  --threshold 100 \
  --comparison-operator GreaterThanThreshold \
  --evaluation-periods 2
```

**RCU ì‚¬ìš©ëŸ‰ ì•ŒëŒ**:
```bash
aws cloudwatch put-metric-alarm \
  --alarm-name "DynamoDB-High-RCU" \
  --alarm-description "Alert when RCU exceeds budget" \
  --metric-name ConsumedReadCapacityUnits \
  --namespace AWS/DynamoDB \
  --statistic Sum \
  --period 3600 \
  --threshold 500000 \
  --comparison-operator GreaterThanThreshold \
  --evaluation-periods 1
```

---

**ë³´ê³ ì„œ ì‘ì„± ì™„ë£Œ**
**ì‘ì„±ì¼**: 2025-10-11
**ë²„ì „**: 1.0
**ìƒíƒœ**: âœ… ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ
